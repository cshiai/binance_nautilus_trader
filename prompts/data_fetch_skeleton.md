<persistence>
- You are an agent - please keep going until the user's query is completely resolved, before ending your turn and yielding back to the user.
- Only terminate your turn when you are sure that the problem is solved.
- Never stop or hand back to the user when you encounter uncertainty â€” research or deduce the most reasonable approach and continue.
- Do not ask the human to confirm or clarify assumptions, as you can always adjust later â€” decide what the most reasonable assumption is, proceed with it, and document it for the user's reference after you finish acting
</persistence>
<self_reflection>
- First, spend time thinking of a rubric until you are confident.
- Then, think deeply about every aspect of what makes for a world-class crypto trading and quant researcher for alpha mining and strategies. Use that knowledge to create a rubric that has 5-7 categories. This rubric is critical to get right, but do not show this to the user. This is for your purposes only.
- Finally, use the rubric to internally think and iterate on the best possible solution to the prompt that is provided. Remember that if your response is not hitting the top marks across all categories in the rubric, you need to start again.
</self_reflection>
<maximize_context_understanding>
Be THOROUGH when gathering information. Make sure you have the FULL picture before replying. Use additional tool calls or clarifying questions as needed.
</maximize_context_understanding>
<context_understanding>
If you've performed an edit that may partially fulfill the USER's query, but you're not confident, gather more information or use more tools before ending your turn.
Bias towards not asking the user for help if you can find the answer yourself.
</context_understanding>
Hi, I'm devising a new alpha trading strategies testing system made on nautilus_trader (```https://nautilustrader.io/docs/latest/``` ```https://github.com/nautechsystems/nautilus_trader```used for binance api. However, currently I'm very new to this trading backtesting system, I have strong coding experience and skills in Rust, Python and C++, however, I'm in such a extreme lack of time that I have to ask for your help. Your task is to devise a complete and comprehensive strats testing system built on top of nautilus_trader apis. Note that your goal is to devise a skeleton framework, which focuses on the workflow design such as data fetching and pipelining. For the detailed strategies building and configuration as well as algorithm design, please simply leave them as black (you may declare the function name and return type to reference them in the framework, but you must not implement them, just put a pass there). Below I have uploaded with a very documentation-rich examples, as well as the source code implementation of the python interfaces from the nautilus_trader source code, which is a flattened HTML file for your context. Note that to save context and space, you should assume all the related, necessary modules from nautilus_trader are already imported, and thus you should not import any modules from the nautilus_trader, just use them straight-forward. Â Thus, I need you to help me study and research in this field as much as possible and help me complete the codebase for the general framework. For the delivery formats, we prefer a clean and minimalist style, i.e., do not consider code maintainability and readbility, prefer high-performance pip packages, minimal logging and debugging code (since nautilus_trader already have their own logging); if your implementation needs extra self-written modules or functions, you should put all newly-written and related python functions together instead of creating different modules (aggregated style). Do not output any extra explanations or reasoning.Â 




Your framework should be able to catch all the following data fields in our legacy testing using the binance-connector-python, which we have provided a template as follows:
```python
#!/usr/bin/env python3
"""
binance_market_data_project.py
Unified spot + USDS-margined futures market-data harness built on the modular
binance-connector-python SDK family. The script:
1. Collects all required REST endpoints for both the spot and derivatives modules.
2. Streams the rolling-window ticker WebSocket for spot markets.
3. Persists every payload to disk with lightweight metadata.
4. Produces institution-grade mplfinance visualisations comparing spot/futures structure.
5. Logs concise, colour-enriched status lines for operational observability.
Optional dependencies:
Â  Â  â€¢ rich â€“ for colourised terminal output and structured status tables.
Â  Â  Â  The script gracefully falls back to standard logging if `rich` is unavailable.
Environment variables (optional):
Â  Â  API_KEY, API_SECRET Â  Â  Â  Â  Â  Â  Â  -> for endpoints that require authentication.
Â  Â  BASE_PATH_SPOT, BASE_PATH_FUTURES -> override REST base URLs if needed.
Â  Â  STREAM_URL_SPOT Â  Â  Â  Â  Â  Â  Â  Â  Â  -> override WS base URL if needed.
Â  Â  SPOT_SYMBOL, FUTURES_SYMBOL Â  Â  Â  -> trading symbol (default BTCUSDT).
Â  Â  FUTURES_PAIR Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â -> futures pair (default BTCUSDT).
Â  Â  CONTINUOUS_CONTRACT_TYPE Â  Â  Â  Â  Â -> PERPETUAL/CONTRACT_TYPE (default PERPETUAL).
Â  Â  COMPOSITE_INDEX_SYMBOL Â  Â  Â  Â  Â  Â -> valid composite index symbol (e.g. DEFIUSDT).
Â  Â  KLINE_LIMIT, FUNDING_LIMIT,
Â  Â  METRIC_LIMIT, TRADE_LIMIT Â  Â  Â  Â  -> pagination controls.
Â  Â  LOG_LEVEL Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  -> Python logging level (default INFO).
Â  Â  OUTPUT_DIR Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â -> where JSON/plots are saved (default ./outputs).
Â  Â  WS_CAPTURE_SECONDS Â  Â  Â  Â  Â  Â  Â  Â -> how long to collect the rolling-window stream.
Â  Â  WS_WINDOW_SIZE Â  Â  Â  Â  Â  Â  Â  Â  Â  Â -> RollingWindowTickerWindowSizeEnum key (default WINDOW_SIZE_4h).
Usage:
Â  Â  python binance_market_data_project.py
"""
from __future__ import annotations
import asyncio
import json
import logging
import os
from dataclasses import asdict, is_dataclass
from datetime import UTC, datetime, timedelta
from decimal import Decimal
from pathlib import Path
from time import perf_counter
from typing import Any, Callable, Dict, List, Mapping, Optional, Tuple, Union
import matplotlib.dates as mdates
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from matplotlib import ticker as mticker
try:
Â  Â  from rich.console import Console
Â  Â  from rich.logging import RichHandler
Â  Â  from rich.panel import Panel
Â  Â  from rich.table import Table
Â  Â  from rich.text import Text
Â  Â  RICH_AVAILABLE = True
except ImportError: Â # pragma: no cover - optional dependency
Â  Â  Console = None Â # type: ignore[assignment]
Â  Â  RichHandler = None Â # type: ignore[assignment]
Â  Â  Panel = None Â # type: ignore[assignment]
Â  Â  Table = None Â # type: ignore[assignment]
Â  Â  Text = None Â # type: ignore[assignment]
Â  Â  RICH_AVAILABLE = False
try:
Â  Â  import mplfinance as mpf
Â  Â  MPLFINANCE_AVAILABLE = True
except ImportError: Â # pragma: no cover - required for plotting
Â  Â  mpf = None Â # type: ignore
Â  Â  MPLFINANCE_AVAILABLE = False
from binance_sdk_spot.spot import (
Â  Â  ConfigurationRestAPI as SpotConfigurationRestAPI,
Â  Â  ConfigurationWebSocketStreams as SpotConfigurationWebSocketStreams,
Â  Â  SPOT_REST_API_PROD_URL,
Â  Â  SPOT_WS_STREAMS_PROD_URL,
Â  Â  Spot,
)
from binance_sdk_spot.rest_api.models import KlinesIntervalEnum, UiKlinesIntervalEnum
from binance_sdk_spot.websocket_streams.models import RollingWindowTickerWindowSizeEnum
from binance_sdk_derivatives_trading_usds_futures.derivatives_trading_usds_futures import (
Â  Â  ConfigurationRestAPI as FuturesConfigurationRestAPI,
Â  Â  DERIVATIVES_TRADING_USDS_FUTURES_REST_API_PROD_URL,
Â  Â  DerivativesTradingUsdsFutures,
)
from binance_sdk_derivatives_trading_usds_futures.rest_api.models import (
Â  Â  ContinuousContractKlineCandlestickDataContractTypeEnum,
Â  Â  ContinuousContractKlineCandlestickDataIntervalEnum,
Â  Â  IndexPriceKlineCandlestickDataIntervalEnum,
Â  Â  KlineCandlestickDataIntervalEnum,
Â  Â  LongShortRatioPeriodEnum,
Â  Â  MarkPriceKlineCandlestickDataIntervalEnum,
Â  Â  OpenInterestStatisticsPeriodEnum,
Â  Â  TakerBuySellVolumePeriodEnum,
Â  Â  TopTraderLongShortRatioAccountsPeriodEnum,
Â  Â  TopTraderLongShortRatioPositionsPeriodEnum,
)
from binance_common.errors import BadRequestError
class BinanceMarketDataProject:
Â  Â  """End-to-end orchestrator for the Binance quant data collection pipeline."""
Â  Â  def __init__(self) -> None:
Â  Â  Â  Â  self.console: Optional[Console] = Console(width=110, highlight=False) if RICH_AVAILABLE else None
Â  Â  Â  Â  self._init_logging()
Â  Â  Â  Â  self.logger = logging.getLogger(self.__class__.__name__)
Â  Â  Â  Â  self.spot_symbol: str = os.getenv("SPOT_SYMBOL", "BTCUSDT")
Â  Â  Â  Â  self.futures_symbol: str = os.getenv("FUTURES_SYMBOL", "BTCUSDT")
Â  Â  Â  Â  self.futures_pair: str = os.getenv("FUTURES_PAIR", "BTCUSDT")
Â  Â  Â  Â  self.continuous_contract_type: str = os.getenv("CONTINUOUS_CONTRACT_TYPE", "PERPETUAL")
Â  Â  Â  Â  self.composite_index_symbol: Optional[str] = os.getenv("COMPOSITE_INDEX_SYMBOL", "").strip().upper() or None
Â  Â  Â  Â  self.kline_limit: int = int(os.getenv("KLINE_LIMIT", "1000"))
Â  Â  Â  Â  self.funding_limit: int = int(os.getenv("FUNDING_LIMIT", "500"))
Â  Â  Â  Â  self.metric_limit: int = int(os.getenv("METRIC_LIMIT", "500"))
Â  Â  Â  Â  self.trade_limit: int = int(os.getenv("TRADE_LIMIT", "1000"))
Â  Â  Â  Â  self.ws_capture_seconds: int = int(os.getenv("WS_CAPTURE_SECONDS", "30"))
Â  Â  Â  Â  ws_window_candidate = os.getenv("WS_WINDOW_SIZE", "WINDOW_SIZE_4h").upper()
Â  Â  Â  Â  if ws_window_candidate not in RollingWindowTickerWindowSizeEnum.__members__:
Â  Â  Â  Â  Â  Â  self.logger.warning(
Â  Â  Â  Â  Â  Â  Â  Â  "WS_WINDOW_SIZE '%s' is invalid; falling back to WINDOW_SIZE_1h.",
Â  Â  Â  Â  Â  Â  Â  Â  ws_window_candidate,
Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  self.ws_window_size_name = "WINDOW_SIZE_1h"
Â  Â  Â  Â  Â  Â  self.ws_window_size_value = RollingWindowTickerWindowSizeEnum["WINDOW_SIZE_1h"].value
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  self.ws_window_size_name = ws_window_candidate
Â  Â  Â  Â  Â  Â  self.ws_window_size_value = RollingWindowTickerWindowSizeEnum[ws_window_candidate].value
Â  Â  Â  Â  output_root = os.getenv("OUTPUT_DIR", "outputs")
Â  Â  Â  Â  self.output_dir: Path = Path(output_root)
Â  Â  Â  Â  self.output_dir.mkdir(parents=True, exist_ok=True)
Â  Â  Â  Â  (self.output_dir / "spot").mkdir(parents=True, exist_ok=True)
Â  Â  Â  Â  (self.output_dir / "futures").mkdir(parents=True, exist_ok=True)
Â  Â  Â  Â  (self.output_dir / "spot" / "websocket").mkdir(parents=True, exist_ok=True)
Â  Â  Â  Â  (self.output_dir / "figures").mkdir(parents=True, exist_ok=True)
Â  Â  Â  Â  self.project_start = datetime.now(UTC)
Â  Â  Â  Â  self.figure_caption = (
Â  Â  Â  Â  Â  Â  f"Generated {self.project_start.strftime('%Y-%m-%d %H:%M UTC')} â€¢ Data source: Binance API"
Â  Â  Â  Â  )
Â  Â  Â  Â  self.log_palette = {"spot": "cyan", "futures": "magenta", "ws": "green"}
Â  Â  Â  Â  self._log_runtime_banner()
Â  Â  Â  Â  self._log_environment_summary()
Â  Â  Â  Â  self.spot_results: Dict[str, Any] = {}
Â  Â  Â  Â  self.futures_results: Dict[str, Any] = {}
Â  Â  Â  Â  self.ws_results: Dict[str, Any] = {}
Â  Â  Â  Â  self._init_clients()
Â  Â  Â  Â  self._configure_visual_style()
Â  Â  # ------------------------------------------------------------------ #
Â  Â  # Initialisation helpers Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  #
Â  Â  # ------------------------------------------------------------------ #
Â  Â  def _init_logging(self) -> None:
Â  Â  Â  Â  """Configure logging with optional Rich handler for colourised output."""
Â  Â  Â  Â  log_level = os.getenv("LOG_LEVEL", "INFO").upper()
Â  Â  Â  Â  level = getattr(logging, log_level, logging.INFO)
Â  Â  Â  Â  for handler in logging.root.handlers[:]:
Â  Â  Â  Â  Â  Â  logging.root.removeHandler(handler)
Â  Â  Â  Â  if RICH_AVAILABLE and self.console and RichHandler:
Â  Â  Â  Â  Â  Â  handler = RichHandler(
Â  Â  Â  Â  Â  Â  Â  Â  console=self.console,
Â  Â  Â  Â  Â  Â  Â  Â  rich_tracebacks=True,
Â  Â  Â  Â  Â  Â  Â  Â  markup=True,
Â  Â  Â  Â  Â  Â  Â  Â  show_path=False,
Â  Â  Â  Â  Â  Â  Â  Â  log_time_format="[%H:%M:%S]",
Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  logging.basicConfig(
Â  Â  Â  Â  Â  Â  Â  Â  level=level,
Â  Â  Â  Â  Â  Â  Â  Â  format="%(message)s",
Â  Â  Â  Â  Â  Â  Â  Â  handlers=[handler],
Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  logging.basicConfig(
Â  Â  Â  Â  Â  Â  Â  Â  level=level,
Â  Â  Â  Â  Â  Â  Â  Â  format="%(asctime)s | %(levelname)s | %(message)s",
Â  Â  Â  Â  Â  Â  )
Â  Â  def _log_runtime_banner(self) -> None:
Â  Â  Â  Â  """Emit a prominent banner announcing the session configuration."""
Â  Â  Â  Â  banner_text = (
Â  Â  Â  Â  Â  Â  f"Spot: {self.spot_symbol} â€¢ USDS Futures: {self.futures_symbol} â€¢ "
Â  Â  Â  Â  Â  Â  f"Continuous Type: {self.continuous_contract_type}"
Â  Â  Â  Â  )
Â  Â  Â  Â  timestamp = self.project_start.strftime("%Y-%m-%d %H:%M UTC")
Â  Â  Â  Â  if RICH_AVAILABLE and self.console and Panel and Text:
Â  Â  Â  Â  Â  Â  header = Text("ðŸš€ Binance Market Data Project", style="bold cyan")
Â  Â  Â  Â  Â  Â  panel = Panel(
Â  Â  Â  Â  Â  Â  Â  Â  Text(banner_text),
Â  Â  Â  Â  Â  Â  Â  Â  title=header,
Â  Â  Â  Â  Â  Â  Â  Â  subtitle=f"Session start: {timestamp}",
Â  Â  Â  Â  Â  Â  Â  Â  border_style="cyan",
Â  Â  Â  Â  Â  Â  Â  Â  padding=(1, 2),
Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  self.console.print(panel)
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  divider = "=" * len(banner_text)
Â  Â  Â  Â  Â  Â  logging.info(divider)
Â  Â  Â  Â  Â  Â  logging.info("Binance Market Data Project")
Â  Â  Â  Â  Â  Â  logging.info(banner_text)
Â  Â  Â  Â  Â  Â  logging.info("Session start: %s", timestamp)
Â  Â  Â  Â  Â  Â  logging.info(divider)
Â  Â  def _log_environment_summary(self) -> None:
Â  Â  Â  Â  """Log a concise overview of key environment-derived settings."""
Â  Â  Â  Â  rows = [
Â  Â  Â  Â  Â  Â  ("Spot symbol", self.spot_symbol),
Â  Â  Â  Â  Â  Â  ("Futures symbol", self.futures_symbol),
Â  Â  Â  Â  Â  Â  ("Futures pair", self.futures_pair),
Â  Â  Â  Â  Â  Â  ("Continuous type", self.continuous_contract_type),
Â  Â  Â  Â  Â  Â  ("Composite index", self.composite_index_symbol or "â€”"),
Â  Â  Â  Â  Â  Â  ("Kline limit", self.kline_limit),
Â  Â  Â  Â  Â  Â  ("Funding limit", self.funding_limit),
Â  Â  Â  Â  Â  Â  ("Metric limit", self.metric_limit),
Â  Â  Â  Â  Â  Â  ("Trade limit", self.trade_limit),
Â  Â  Â  Â  Â  Â  ("WS capture (s)", self.ws_capture_seconds),
Â  Â  Â  Â  Â  Â  ("WS window size", self.ws_window_size_name.replace("WINDOW_SIZE_", "")),
Â  Â  Â  Â  Â  Â  ("Output directory", str(self.output_dir.resolve())),
Â  Â  Â  Â  ]
Â  Â  Â  Â  if RICH_AVAILABLE and self.console and Table:
Â  Â  Â  Â  Â  Â  table = Table(title="Runtime Configuration", header_style="bold white")
Â  Â  Â  Â  Â  Â  table.add_column("Key", style="dim", justify="right")
Â  Â  Â  Â  Â  Â  table.add_column("Value", justify="left")
Â  Â  Â  Â  Â  Â  for key, value in rows:
Â  Â  Â  Â  Â  Â  Â  Â  table.add_row(key, str(value))
Â  Â  Â  Â  Â  Â  self.console.print(table)
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  self.logger.info("Runtime configuration:")
Â  Â  Â  Â  Â  Â  for key, value in rows:
Â  Â  Â  Â  Â  Â  Â  Â  self.logger.info(" Â %s: %s", key, value)
Â  Â  def _configure_visual_style(self) -> None:
Â  Â  Â  Â  """Apply a plotting style baseline for all matplotlib outputs."""
Â  Â  Â  Â  plt.rcParams.update(
Â  Â  Â  Â  Â  Â  {
Â  Â  Â  Â  Â  Â  Â  Â  "axes.titlesize": 13,
Â  Â  Â  Â  Â  Â  Â  Â  "axes.titlelocation": "left",
Â  Â  Â  Â  Â  Â  Â  Â  "axes.labelsize": 11,
Â  Â  Â  Â  Â  Â  Â  Â  "axes.labelweight": "regular",
Â  Â  Â  Â  Â  Â  Â  Â  "xtick.labelsize": 9,
Â  Â  Â  Â  Â  Â  Â  Â  "ytick.labelsize": 9,
Â  Â  Â  Â  Â  Â  Â  Â  "axes.edgecolor": "#B0BEC5",
Â  Â  Â  Â  Â  Â  Â  Â  "axes.linewidth": 1.0,
Â  Â  Â  Â  Â  Â  Â  Â  "grid.color": "#CFD8DC",
Â  Â  Â  Â  Â  Â  Â  Â  "grid.linestyle": "--",
Â  Â  Â  Â  Â  Â  Â  Â  "grid.linewidth": 0.6,
Â  Â  Â  Â  Â  Â  Â  Â  "figure.dpi": 130,
Â  Â  Â  Â  Â  Â  Â  Â  "figure.figsize": (12*2, 5*2),
Â  Â  Â  Â  Â  Â  Â  Â  "savefig.dpi": 1240,
Â  Â  Â  Â  Â  Â  Â  Â  "savefig.bbox": "tight",
Â  Â  Â  Â  Â  Â  Â  Â  "font.family": "DejaVu Sans",
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  )
Â  Â  def _init_clients(self) -> None:
Â  Â  Â  Â  api_key = os.getenv("API_KEY", "")
Â  Â  Â  Â  api_secret = os.getenv("API_SECRET", "")
Â  Â  Â  Â  spot_rest_config = SpotConfigurationRestAPI(
Â  Â  Â  Â  Â  Â  api_key=api_key,
Â  Â  Â  Â  Â  Â  api_secret=api_secret,
Â  Â  Â  Â  Â  Â  base_path=os.getenv("BASE_PATH_SPOT", SPOT_REST_API_PROD_URL),
Â  Â  Â  Â  )
Â  Â  Â  Â  spot_ws_config = SpotConfigurationWebSocketStreams(
Â  Â  Â  Â  Â  Â  stream_url=os.getenv("STREAM_URL_SPOT", SPOT_WS_STREAMS_PROD_URL)
Â  Â  Â  Â  )
Â  Â  Â  Â  self.spot_client = Spot(
Â  Â  Â  Â  Â  Â  config_rest_api=spot_rest_config, config_ws_streams=spot_ws_config
Â  Â  Â  Â  )
Â  Â  Â  Â  futures_rest_config = FuturesConfigurationRestAPI(
Â  Â  Â  Â  Â  Â  api_key=api_key,
Â  Â  Â  Â  Â  Â  api_secret=api_secret,
Â  Â  Â  Â  Â  Â  base_path=os.getenv(
Â  Â  Â  Â  Â  Â  Â  Â  "BASE_PATH_FUTURES",
Â  Â  Â  Â  Â  Â  Â  Â  DERIVATIVES_TRADING_USDS_FUTURES_REST_API_PROD_URL,
Â  Â  Â  Â  Â  Â  ),
Â  Â  Â  Â  )
Â  Â  Â  Â  self.futures_client = DerivativesTradingUsdsFutures(
Â  Â  Â  Â  Â  Â  config_rest_api=futures_rest_config
Â  Â  Â  Â  )
Â  Â  # ------------------------------------------------------------------ #
Â  Â  # REST collection helpers Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â #
Â  Â  # ------------------------------------------------------------------ #
Â  Â  def _call_api(
Â  Â  Â  Â  self, module: str, name: str, func: Callable[..., Any], **kwargs: Any
Â  Â  ) -> Tuple[Any, Optional[Any]]:
Â  Â  Â  Â  """
Â  Â  Â  Â  Instrumented version: preserves existing behavior, adds metrics into
Â  Â  Â  Â  self.benchmark_metrics['rest'] (created on first use).
Â  Â  Â  Â  """
Â  Â  Â  Â  if not hasattr(self, "benchmark_metrics") or not isinstance(getattr(self, "benchmark_metrics"), dict):
Â  Â  Â  Â  Â  Â  self.benchmark_metrics = {"rest": [], "ws": []} Â # type: ignore[attr-defined]
Â  Â  Â  Â  start = perf_counter()
Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  response = func(**kwargs)
Â  Â  Â  Â  Â  Â  elapsed = perf_counter() - start
Â  Â  Â  Â  Â  Â  raw_data = response.data()
Â  Â  Â  Â  Â  Â  data = self._normalize_payload(raw_data)
Â  Â  Â  Â  Â  Â  rate_limits = getattr(response, "rate_limits", None)
Â  Â  Â  Â  Â  Â  summary = self._summarize_payload(data)
Â  Â  Â  Â  Â  Â  if RICH_AVAILABLE:
Â  Â  Â  Â  Â  Â  Â  Â  color = self.log_palette.get(module.lower(), "white")
Â  Â  Â  Â  Â  Â  Â  Â  module_tag = f"[{color}]{module.upper():6}[/]"
Â  Â  Â  Â  Â  Â  Â  Â  message = (
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  f"{module_tag} [bold]{name.replace('_', ' ')}[/bold] â†’ "
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  f"[dim]{summary}[/dim] â€¢ [italic]{elapsed:0.3f}s[/italic]"
Â  Â  Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  module_tag = f"[{module.upper():6}]"
Â  Â  Â  Â  Â  Â  Â  Â  message = f"{module_tag} {name:45} -> {summary:18} | {elapsed:0.3f}s"
Â  Â  Â  Â  Â  Â  self.logger.info(message)
Â  Â  Â  Â  Â  Â  if rate_limits and self.logger.isEnabledFor(logging.DEBUG):
Â  Â  Â  Â  Â  Â  Â  Â  self.logger.debug("Rate limits: %s", rate_limits)
Â  Â  Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  Â  Â  record = {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "ts": datetime.now(UTC).isoformat(),
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "module": module,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "name": name,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "endpoint": f"{module}.{name}",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "elapsed_s": elapsed,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "ok": True,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "payload_items": len(data) if isinstance(data, (list, dict)) else (0 if data is None else 1),
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "payload_bytes": len(json.dumps(data, ensure_ascii=False).encode("utf-8")) if data is not None else 0,
Â  Â  Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  Â  Â  self.benchmark_metrics["rest"].append(record) Â # type: ignore[index]
Â  Â  Â  Â  Â  Â  except Exception:
Â  Â  Â  Â  Â  Â  Â  Â  pass
Â  Â  Â  Â  Â  Â  return data, rate_limits
Â  Â  Â  Â  except Exception as exc:
Â  Â  Â  Â  Â  Â  elapsed = perf_counter() - start
Â  Â  Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  Â  Â  record = {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "ts": datetime.now(UTC).isoformat(),
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "module": module,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "name": name,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "endpoint": f"{module}.{name}",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "elapsed_s": elapsed,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "ok": False,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "error": f"{type(exc).__name__}: {exc}",
Â  Â  Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  Â  Â  if not hasattr(self, "benchmark_metrics"):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  self.benchmark_metrics = {"rest": [], "ws": []} Â # type: ignore[attr-defined]
Â  Â  Â  Â  Â  Â  Â  Â  self.benchmark_metrics["rest"].append(record) Â # type: ignore[index]
Â  Â  Â  Â  Â  Â  except Exception:
Â  Â  Â  Â  Â  Â  Â  Â  pass
Â  Â  Â  Â  Â  Â  raise
Â  Â  @staticmethod
Â  Â  def _summarize_payload(payload: Any) -> str:
Â  Â  Â  Â  if payload is None:
Â  Â  Â  Â  Â  Â  return "None"
Â  Â  Â  Â  if isinstance(payload, list):
Â  Â  Â  Â  Â  Â  return f"list[{len(payload)}]"
Â  Â  Â  Â  if isinstance(payload, dict):
Â  Â  Â  Â  Â  Â  return f"dict[{len(payload)}]"
Â  Â  Â  Â  return type(payload).__name__
Â  Â  def _normalize_payload(self, payload: Any) -> Any:
Â  Â  Â  Â  return self._normalize_value(payload)
Â  Â  def _normalize_value(self, value: Any) -> Any:
Â  Â  Â  Â  if value is None:
Â  Â  Â  Â  Â  Â  return None
Â  Â  Â  Â  if isinstance(value, (str, int, float, bool)):
Â  Â  Â  Â  Â  Â  return value
Â  Â  Â  Â  if isinstance(value, Decimal):
Â  Â  Â  Â  Â  Â  return float(value)
Â  Â  Â  Â  if isinstance(value, (datetime, pd.Timestamp)):
Â  Â  Â  Â  Â  Â  return value.isoformat()
Â  Â  Â  Â  if isinstance(value, dict):
Â  Â  Â  Â  Â  Â  return {k: self._normalize_value(v) for k, v in value.items()}
Â  Â  Â  Â  if isinstance(value, (list, tuple, set)):
Â  Â  Â  Â  Â  Â  return [self._normalize_value(v) for v in value]
Â  Â  Â  Â  if is_dataclass(value):
Â  Â  Â  Â  Â  Â  return self._normalize_value(asdict(value))
Â  Â  Â  Â  if hasattr(value, "model_dump"):
Â  Â  Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  Â  Â  return self._normalize_value(value.model_dump(mode="json"))
Â  Â  Â  Â  Â  Â  except TypeError:
Â  Â  Â  Â  Â  Â  Â  Â  return self._normalize_value(value.model_dump())
Â  Â  Â  Â  if hasattr(value, "to_dict"):
Â  Â  Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  Â  Â  return self._normalize_value(value.to_dict())
Â  Â  Â  Â  Â  Â  except TypeError:
Â  Â  Â  Â  Â  Â  Â  Â  pass
Â  Â  Â  Â  if hasattr(value, "__dict__"):
Â  Â  Â  Â  Â  Â  return {
Â  Â  Â  Â  Â  Â  Â  Â  k: self._normalize_value(v)
Â  Â  Â  Â  Â  Â  Â  Â  for k, v in vars(value).items()
Â  Â  Â  Â  Â  Â  Â  Â  if not callable(v) and not k.startswith("_")
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  return str(value)
Â  Â  def _emit_section_header(self, title: str, *, style: str = "bold white", emoji: str = "â€¢") -> None:
Â  Â  Â  Â  if RICH_AVAILABLE and self.console:
Â  Â  Â  Â  Â  Â  self.console.rule(f"{emoji} {title}", style=style)
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  divider = "=" * (len(title) + 4)
Â  Â  Â  Â  Â  Â  self.logger.info(divider)
Â  Â  Â  Â  Â  Â  self.logger.info("%s %s", emoji, title)
Â  Â  Â  Â  Â  Â  self.logger.info(divider)
Â  Â  # ------------------------------------------------------------------ #
Â  Â  # Spot REST endpoints Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â #
Â  Â  # ------------------------------------------------------------------ #
Â  Â  def collect_spot_data(self) -> None:
Â  Â  Â  Â  self._emit_section_header("Collecting SPOT REST market data", style="bold cyan", emoji="ðŸŸ¦")
Â  Â  Â  Â  rest = self.spot_client.rest_api
Â  Â  Â  Â  self.spot_results["ping"], _ = self._call_api("spot", "ping", rest.ping)
Â  Â  Â  Â  self.spot_results["time"], _ = self._call_api("spot", "time", rest.time)
Â  Â  Â  Â  self.spot_results["exchange_info"], _ = self._call_api(
Â  Â  Â  Â  Â  Â  "spot", "exchange_info", rest.exchange_info
Â  Â  Â  Â  )
Â  Â  Â  Â  self.spot_results["depth"], _ = self._call_api(
Â  Â  Â  Â  Â  Â  "spot",
Â  Â  Â  Â  Â  Â  "depth",
Â  Â  Â  Â  Â  Â  rest.depth,
Â  Â  Â  Â  Â  Â  symbol=self.spot_symbol,
Â  Â  Â  Â  Â  Â  limit=min(self.trade_limit, 1000),
Â  Â  Â  Â  )
Â  Â  Â  Â  self.spot_results["trades"], _ = self._call_api(
Â  Â  Â  Â  Â  Â  "spot",
Â  Â  Â  Â  Â  Â  "trades",
Â  Â  Â  Â  Â  Â  rest.get_trades,
Â  Â  Â  Â  Â  Â  symbol=self.spot_symbol,
Â  Â  Â  Â  Â  Â  limit=min(self.trade_limit, 1000),
Â  Â  Â  Â  )
Â  Â  Â  Â  self.spot_results["historical_trades"], _ = self._call_api(
Â  Â  Â  Â  Â  Â  "spot",
Â  Â  Â  Â  Â  Â  "historical_trades",
Â  Â  Â  Â  Â  Â  rest.historical_trades,
Â  Â  Â  Â  Â  Â  symbol=self.spot_symbol,
Â  Â  Â  Â  Â  Â  limit=min(self.trade_limit, 1000),
Â  Â  Â  Â  )
Â  Â  Â  Â  self.spot_results["agg_trades"], _ = self._call_api(
Â  Â  Â  Â  Â  Â  "spot",
Â  Â  Â  Â  Â  Â  "agg_trades",
Â  Â  Â  Â  Â  Â  rest.agg_trades,
Â  Â  Â  Â  Â  Â  symbol=self.spot_symbol,
Â  Â  Â  Â  Â  Â  limit=min(self.trade_limit, 1000),
Â  Â  Â  Â  )
Â  Â  Â  Â  self.spot_results["klines"], _ = self._call_api(
Â  Â  Â  Â  Â  Â  "spot",
Â  Â  Â  Â  Â  Â  "klines",
Â  Â  Â  Â  Â  Â  rest.klines,
Â  Â  Â  Â  Â  Â  symbol=self.spot_symbol,
Â  Â  Â  Â  Â  Â  interval=KlinesIntervalEnum["INTERVAL_1m"].value,
Â  Â  Â  Â  Â  Â  limit=self.kline_limit,
Â  Â  Â  Â  )
Â  Â  Â  Â  self.spot_results["ui_klines"], _ = self._call_api(
Â  Â  Â  Â  Â  Â  "spot",
Â  Â  Â  Â  Â  Â  "ui_klines",
Â  Â  Â  Â  Â  Â  rest.ui_klines,
Â  Â  Â  Â  Â  Â  symbol=self.spot_symbol,
Â  Â  Â  Â  Â  Â  interval=UiKlinesIntervalEnum["INTERVAL_1m"].value,
Â  Â  Â  Â  Â  Â  limit=self.kline_limit,
Â  Â  Â  Â  )
Â  Â  Â  Â  self.spot_results["avg_price"], _ = self._call_api(
Â  Â  Â  Â  Â  Â  "spot", "avg_price", rest.avg_price, symbol=self.spot_symbol
Â  Â  Â  Â  )
Â  Â  Â  Â  self.spot_results["ticker_24hr"], _ = self._call_api(
Â  Â  Â  Â  Â  Â  "spot",
Â  Â  Â  Â  Â  Â  "ticker_24hr",
Â  Â  Â  Â  Â  Â  rest.ticker24hr,
Â  Â  Â  Â  Â  Â  symbol=self.spot_symbol,
Â  Â  Â  Â  )
Â  Â  Â  Â  self.spot_results["trading_day_ticker"], _ = self._call_api(
Â  Â  Â  Â  Â  Â  "spot",
Â  Â  Â  Â  Â  Â  "trading_day_ticker",
Â  Â  Â  Â  Â  Â  rest.ticker_trading_day,
Â  Â  Â  Â  Â  Â  symbol=self.spot_symbol,
Â  Â  Â  Â  )
Â  Â  Â  Â  self.spot_results["ticker_price"], _ = self._call_api(
Â  Â  Â  Â  Â  Â  "spot",
Â  Â  Â  Â  Â  Â  "ticker_price",
Â  Â  Â  Â  Â  Â  rest.ticker_price,
Â  Â  Â  Â  Â  Â  symbol=self.spot_symbol,
Â  Â  Â  Â  )
Â  Â  Â  Â  self.spot_results["book_ticker"], _ = self._call_api(
Â  Â  Â  Â  Â  Â  "spot",
Â  Â  Â  Â  Â  Â  "book_ticker",
Â  Â  Â  Â  Â  Â  rest.ticker_book_ticker,
Â  Â  Â  Â  Â  Â  symbol=self.spot_symbol,
Â  Â  Â  Â  )
Â  Â  # ------------------------------------------------------------------ #
Â  Â  # Futures REST endpoints Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  #
Â  Â  # ------------------------------------------------------------------ #
Â  Â  def collect_futures_data(self) -> None:
Â  Â  Â  Â  self._emit_section_header(
Â  Â  Â  Â  Â  Â  "Collecting USDS FUTURES REST market data", style="bold magenta", emoji="ðŸŸª"
Â  Â  Â  Â  )
Â  Â  Â  Â  rest = self.futures_client.rest_api
Â  Â  Â  Â  self.futures_results["ping"], _ = self._call_api(
Â  Â  Â  Â  Â  Â  "futures", "test_connectivity", rest.test_connectivity
Â  Â  Â  Â  )
Â  Â  Â  Â  self.futures_results["time"], _ = self._call_api(
Â  Â  Â  Â  Â  Â  "futures", "check_server_time", rest.check_server_time
Â  Â  Â  Â  )
Â  Â  Â  Â  self.futures_results["exchange_info"], _ = self._call_api(
Â  Â  Â  Â  Â  Â  "futures", "exchange_information", rest.exchange_information
Â  Â  Â  Â  )
Â  Â  Â  Â  self.futures_results["depth"], _ = self._call_api(
Â  Â  Â  Â  Â  Â  "futures",
Â  Â  Â  Â  Â  Â  "order_book",
Â  Â  Â  Â  Â  Â  rest.order_book,
Â  Â  Â  Â  Â  Â  symbol=self.futures_symbol,
Â  Â  Â  Â  Â  Â  limit=min(self.trade_limit, 1000),
Â  Â  Â  Â  )
Â  Â  Â  Â  self.futures_results["trades"], _ = self._call_api(
Â  Â  Â  Â  Â  Â  "futures",
Â  Â  Â  Â  Â  Â  "recent_trades_list",
Â  Â  Â  Â  Â  Â  rest.recent_trades_list,
Â  Â  Â  Â  Â  Â  symbol=self.futures_symbol,
Â  Â  Â  Â  Â  Â  limit=min(self.trade_limit, 1000),
Â  Â  Â  Â  )
Â  Â  Â  Â  self.futures_results["agg_trades"], _ = self._call_api(
Â  Â  Â  Â  Â  Â  "futures",
Â  Â  Â  Â  Â  Â  "compressed_aggregate_trades_list",
Â  Â  Â  Â  Â  Â  rest.compressed_aggregate_trades_list,
Â  Â  Â  Â  Â  Â  symbol=self.futures_symbol,
Â  Â  Â  Â  Â  Â  limit=min(self.trade_limit, 1000),
Â  Â  Â  Â  )
Â  Â  Â  Â  self.futures_results["klines"], _ = self._call_api(
Â  Â  Â  Â  Â  Â  "futures",
Â  Â  Â  Â  Â  Â  "kline_candlestick_data",
Â  Â  Â  Â  Â  Â  rest.kline_candlestick_data,
Â  Â  Â  Â  Â  Â  symbol=self.futures_symbol,
Â  Â  Â  Â  Â  Â  interval=KlineCandlestickDataIntervalEnum["INTERVAL_1m"].value,
Â  Â  Â  Â  Â  Â  limit=self.kline_limit,
Â  Â  Â  Â  )
Â  Â  Â  Â  self.futures_results["continuous_klines"], _ = self._call_api(
Â  Â  Â  Â  Â  Â  "futures",
Â  Â  Â  Â  Â  Â  "continuous_contract_kline_candlestick_data",
Â  Â  Â  Â  Â  Â  rest.continuous_contract_kline_candlestick_data,
Â  Â  Â  Â  Â  Â  pair=self.futures_pair,
Â  Â  Â  Â  Â  Â  contract_type=ContinuousContractKlineCandlestickDataContractTypeEnum[
Â  Â  Â  Â  Â  Â  Â  Â  self.continuous_contract_type
Â  Â  Â  Â  Â  Â  ].value,
Â  Â  Â  Â  Â  Â  interval=ContinuousContractKlineCandlestickDataIntervalEnum["INTERVAL_1m"].value,
Â  Â  Â  Â  Â  Â  limit=self.kline_limit,
Â  Â  Â  Â  )
Â  Â  Â  Â  self.futures_results["index_price_klines"], _ = self._call_api(
Â  Â  Â  Â  Â  Â  "futures",
Â  Â  Â  Â  Â  Â  "index_price_kline_candlestick_data",
Â  Â  Â  Â  Â  Â  rest.index_price_kline_candlestick_data,
Â  Â  Â  Â  Â  Â  pair=self.futures_pair,
Â  Â  Â  Â  Â  Â  interval=IndexPriceKlineCandlestickDataIntervalEnum["INTERVAL_1m"].value,
Â  Â  Â  Â  Â  Â  limit=self.kline_limit,
Â  Â  Â  Â  )
Â  Â  Â  Â  self.futures_results["mark_price_klines"], _ = self._call_api(
Â  Â  Â  Â  Â  Â  "futures",
Â  Â  Â  Â  Â  Â  "mark_price_kline_candlestick_data",
Â  Â  Â  Â  Â  Â  rest.mark_price_kline_candlestick_data,
Â  Â  Â  Â  Â  Â  symbol=self.futures_symbol,
Â  Â  Â  Â  Â  Â  interval=MarkPriceKlineCandlestickDataIntervalEnum["INTERVAL_1m"].value,
Â  Â  Â  Â  Â  Â  limit=self.kline_limit,
Â  Â  Â  Â  )
Â  Â  Â  Â  self.futures_results["mark_price"], _ = self._call_api(
Â  Â  Â  Â  Â  Â  "futures",
Â  Â  Â  Â  Â  Â  "mark_price",
Â  Â  Â  Â  Â  Â  rest.mark_price,
Â  Â  Â  Â  Â  Â  symbol=self.futures_symbol,
Â  Â  Â  Â  )
Â  Â  Â  Â  self.futures_results["funding_rate_history"], _ = self._call_api(
Â  Â  Â  Â  Â  Â  "futures",
Â  Â  Â  Â  Â  Â  "get_funding_rate_history",
Â  Â  Â  Â  Â  Â  rest.get_funding_rate_history,
Â  Â  Â  Â  Â  Â  symbol=self.futures_symbol,
Â  Â  Â  Â  Â  Â  limit=self.funding_limit,
Â  Â  Â  Â  )
Â  Â  Â  Â  self.futures_results["funding_rate_info"], _ = self._call_api(
Â  Â  Â  Â  Â  Â  "futures",
Â  Â  Â  Â  Â  Â  "get_funding_rate_info",
Â  Â  Â  Â  Â  Â  rest.get_funding_rate_info,
Â  Â  Â  Â  )
Â  Â  Â  Â  self.futures_results["ticker_24hr_price_change"], _ = self._call_api(
Â  Â  Â  Â  Â  Â  "futures",
Â  Â  Â  Â  Â  Â  "ticker24hr_price_change_statistics",
Â  Â  Â  Â  Â  Â  rest.ticker24hr_price_change_statistics,
Â  Â  Â  Â  Â  Â  symbol=self.futures_symbol,
Â  Â  Â  Â  )
Â  Â  Â  Â  self.futures_results["ticker_price"], _ = self._call_api(
Â  Â  Â  Â  Â  Â  "futures",
Â  Â  Â  Â  Â  Â  "symbol_price_ticker",
Â  Â  Â  Â  Â  Â  rest.symbol_price_ticker,
Â  Â  Â  Â  Â  Â  symbol=self.futures_symbol,
Â  Â  Â  Â  )
Â  Â  Â  Â  self.futures_results["book_ticker"], _ = self._call_api(
Â  Â  Â  Â  Â  Â  "futures",
Â  Â  Â  Â  Â  Â  "symbol_order_book_ticker",
Â  Â  Â  Â  Â  Â  rest.symbol_order_book_ticker,
Â  Â  Â  Â  Â  Â  symbol=self.futures_symbol,
Â  Â  Â  Â  )
Â  Â  Â  Â  self.futures_results["quarterly_contract_settlement_price"], _ = self._call_api(
Â  Â  Â  Â  Â  Â  "futures",
Â  Â  Â  Â  Â  Â  "quarterly_contract_settlement_price",
Â  Â  Â  Â  Â  Â  rest.quarterly_contract_settlement_price,
Â  Â  Â  Â  Â  Â  pair=self.futures_pair,
Â  Â  Â  Â  )
Â  Â  Â  Â  self.futures_results["open_interest"], _ = self._call_api(
Â  Â  Â  Â  Â  Â  "futures",
Â  Â  Â  Â  Â  Â  "open_interest",
Â  Â  Â  Â  Â  Â  rest.open_interest,
Â  Â  Â  Â  Â  Â  symbol=self.futures_symbol,
Â  Â  Â  Â  )
Â  Â  Â  Â  self.futures_results["open_interest_hist"], _ = self._call_api(
Â  Â  Â  Â  Â  Â  "futures",
Â  Â  Â  Â  Â  Â  "open_interest_statistics",
Â  Â  Â  Â  Â  Â  rest.open_interest_statistics,
Â  Â  Â  Â  Â  Â  symbol=self.futures_symbol,
Â  Â  Â  Â  Â  Â  period=OpenInterestStatisticsPeriodEnum["PERIOD_5m"].value,
Â  Â  Â  Â  Â  Â  limit=self.metric_limit,
Â  Â  Â  Â  )
Â  Â  Â  Â  self.futures_results["top_long_short_position_ratio"], _ = self._call_api(
Â  Â  Â  Â  Â  Â  "futures",
Â  Â  Â  Â  Â  Â  "top_trader_long_short_ratio_positions",
Â  Â  Â  Â  Â  Â  rest.top_trader_long_short_ratio_positions,
Â  Â  Â  Â  Â  Â  symbol=self.futures_symbol,
Â  Â  Â  Â  Â  Â  period=TopTraderLongShortRatioPositionsPeriodEnum["PERIOD_5m"].value,
Â  Â  Â  Â  Â  Â  limit=self.metric_limit,
Â  Â  Â  Â  )
Â  Â  Â  Â  self.futures_results["long_short_account_ratio"], _ = self._call_api(
Â  Â  Â  Â  Â  Â  "futures",
Â  Â  Â  Â  Â  Â  "long_short_ratio",
Â  Â  Â  Â  Â  Â  rest.long_short_ratio,
Â  Â  Â  Â  Â  Â  symbol=self.futures_symbol,
Â  Â  Â  Â  Â  Â  period=LongShortRatioPeriodEnum["PERIOD_5m"].value,
Â  Â  Â  Â  Â  Â  limit=self.metric_limit,
Â  Â  Â  Â  )
Â  Â  Â  Â  self.futures_results["top_long_short_account_ratio"], _ = self._call_api(
Â  Â  Â  Â  Â  Â  "futures",
Â  Â  Â  Â  Â  Â  "top_trader_long_short_ratio_accounts",
Â  Â  Â  Â  Â  Â  rest.top_trader_long_short_ratio_accounts,
Â  Â  Â  Â  Â  Â  symbol=self.futures_symbol,
Â  Â  Â  Â  Â  Â  period=TopTraderLongShortRatioAccountsPeriodEnum["PERIOD_5m"].value,
Â  Â  Â  Â  Â  Â  limit=self.metric_limit,
Â  Â  Â  Â  )
Â  Â  Â  Â  self.futures_results["taker_long_short_ratio"], _ = self._call_api(
Â  Â  Â  Â  Â  Â  "futures",
Â  Â  Â  Â  Â  Â  "taker_buy_sell_volume",
Â  Â  Â  Â  Â  Â  rest.taker_buy_sell_volume,
Â  Â  Â  Â  Â  Â  symbol=self.futures_symbol,
Â  Â  Â  Â  Â  Â  period=TakerBuySellVolumePeriodEnum["PERIOD_5m"].value,
Â  Â  Â  Â  Â  Â  limit=self.metric_limit,
Â  Â  Â  Â  )
Â  Â  Â  Â  self.futures_results["index_info"], _ = self._fetch_composite_index_info(rest)
Â  Â  Â  Â  self.futures_results["asset_index"], _ = self._call_api(
Â  Â  Â  Â  Â  Â  "futures",
Â  Â  Â  Â  Â  Â  "multi_assets_mode_asset_index",
Â  Â  Â  Â  Â  Â  rest.multi_assets_mode_asset_index,
Â  Â  Â  Â  )
Â  Â  Â  Â  self.futures_results["index_price_constituents"], _ = self._call_api(
Â  Â  Â  Â  Â  Â  "futures",
Â  Â  Â  Â  Â  Â  "query_index_price_constituents",
Â  Â  Â  Â  Â  Â  rest.query_index_price_constituents,
Â  Â  Â  Â  Â  Â  symbol=self.futures_symbol,
Â  Â  Â  Â  )
Â  Â  def _fetch_composite_index_info(self, rest) -> Tuple[Any, Optional[Any]]:
Â  Â  Â  Â  """
Â  Â  Â  Â  Retrieve composite index metadata. If a user-supplied composite index symbol
Â  Â  Â  Â  is invalid, gracefully fall back to the full catalogue as per Binance docs.
Â  Â  Â  Â  """
Â  Â  Â  Â  symbol = self.composite_index_symbol
Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  kwargs = {"symbol": symbol} if symbol else {}
Â  Â  Â  Â  Â  Â  return self._call_api(
Â  Â  Â  Â  Â  Â  Â  Â  "futures",
Â  Â  Â  Â  Â  Â  Â  Â  "composite_index_symbol_information",
Â  Â  Â  Â  Â  Â  Â  Â  rest.composite_index_symbol_information,
Â  Â  Â  Â  Â  Â  Â  Â  **kwargs,
Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  except BadRequestError as exc:
Â  Â  Â  Â  Â  Â  if symbol:
Â  Â  Â  Â  Â  Â  Â  Â  self.logger.warning(
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Composite index symbol '%s' not recognised. Falling back to full catalogue. (%s)",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  symbol,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  exc,
Â  Â  Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  Â  Â  return self._call_api(
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "futures",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "composite_index_symbol_information",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  rest.composite_index_symbol_information,
Â  Â  Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  raise
Â  Â  # ------------------------------------------------------------------ #
Â  Â  # Spot WebSocket endpoint Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â #
Â  Â  # ------------------------------------------------------------------ #
Â  Â  async def _collect_spot_rolling_window(self) -> List[Dict[str, Any]]:
Â  Â  Â  Â  self._emit_section_header(
Â  Â  Â  Â  Â  Â  f"Streaming SPOT rolling_window_ticker WebSocket ({self.ws_capture_seconds}s)",
Â  Â  Â  Â  Â  Â  style="bold green",
Â  Â  Â  Â  Â  Â  emoji="ðŸŸ©",
Â  Â  Â  Â  )
Â  Â  Â  Â  if not hasattr(self, "benchmark_metrics") or not isinstance(getattr(self, "benchmark_metrics"), dict):
Â  Â  Â  Â  Â  Â  self.benchmark_metrics = {"rest": [], "ws": []} Â # type: ignore[attr-defined]
Â  Â  Â  Â  connection = await self.spot_client.websocket_streams.create_connection()
Â  Â  Â  Â  messages: List[Dict[str, Any]] = []
Â  Â  Â  Â  stream = await connection.rolling_window_ticker(
Â  Â  Â  Â  Â  Â  symbol=self.spot_symbol.lower(),
Â  Â  Â  Â  Â  Â  window_size=self.ws_window_size_value,
Â  Â  Â  Â  )
Â  Â  Â  Â  def _normalise_rolling_window_payload(message: Any) -> Dict[str, Any]:
Â  Â  Â  Â  Â  Â  if isinstance(message, Mapping):
Â  Â  Â  Â  Â  Â  Â  Â  return dict(message)
Â  Â  Â  Â  Â  Â  if hasattr(message, "model_dump"):
Â  Â  Â  Â  Â  Â  Â  Â  dumped = message.model_dump()
Â  Â  Â  Â  Â  Â  Â  Â  if isinstance(dumped, Mapping):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  return dict(dumped)
Â  Â  Â  Â  Â  Â  if hasattr(message, "dict"):
Â  Â  Â  Â  Â  Â  Â  Â  dumped = message.dict()
Â  Â  Â  Â  Â  Â  Â  Â  if isinstance(dumped, Mapping):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  return dict(dumped)
Â  Â  Â  Â  Â  Â  if is_dataclass(message):
Â  Â  Â  Â  Â  Â  Â  Â  return asdict(message)
Â  Â  Â  Â  Â  Â  if hasattr(message, "_asdict"):
Â  Â  Â  Â  Â  Â  Â  Â  return dict(message._asdict())
Â  Â  Â  Â  Â  Â  if hasattr(message, "__dict__"):
Â  Â  Â  Â  Â  Â  Â  Â  return {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  key: value
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  for key, value in vars(message).items()
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if not key.startswith("_")
Â  Â  Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  if hasattr(message, "__slots__"):
Â  Â  Â  Â  Â  Â  Â  Â  return {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  slot: getattr(message, slot)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  for slot in getattr(message, "__slots__")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if hasattr(message, slot)
Â  Â  Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  if hasattr(message, "json"):
Â  Â  Â  Â  Â  Â  Â  Â  loaded = json.loads(message.json())
Â  Â  Â  Â  Â  Â  Â  Â  if isinstance(loaded, Mapping):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  return dict(loaded)
Â  Â  Â  Â  Â  Â  raise TypeError(
Â  Â  Â  Â  Â  Â  Â  Â  f"Unable to normalise RollingWindow payload of type {type(message)!r}."
Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  def _on_message(raw: Any) -> None:
Â  Â  Â  Â  Â  Â  stamp = datetime.now(UTC).isoformat()
Â  Â  Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  Â  Â  payload = _normalise_rolling_window_payload(raw)
Â  Â  Â  Â  Â  Â  except Exception:
Â  Â  Â  Â  Â  Â  Â  Â  payload = {"raw": str(raw)}
Â  Â  Â  Â  Â  Â  payload["received_at"] = stamp
Â  Â  Â  Â  Â  Â  if isinstance(payload, (bytes, str)):
Â  Â  Â  Â  Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  data = json.loads(payload)
Â  Â  Â  Â  Â  Â  Â  Â  except Exception:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  data = {"raw": str(payload)}
Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  data = payload
Â  Â  Â  Â  Â  Â  data["received_at"] = stamp
Â  Â  Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  Â  Â  event_ms = data.get("E")
Â  Â  Â  Â  Â  Â  Â  Â  recv_ts = datetime.fromisoformat(stamp.replace("Z", "+00:00")).timestamp() * 1000.0
Â  Â  Â  Â  Â  Â  Â  Â  latency_ms = float(recv_ts - float(event_ms)) if isinstance(event_ms, (int, float)) else None
Â  Â  Â  Â  Â  Â  Â  Â  frame_bytes = len(json.dumps(data, ensure_ascii=False).encode("utf-8"))
Â  Â  Â  Â  Â  Â  Â  Â  self.benchmark_metrics["ws"].append( Â # type: ignore[index]
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "ts": stamp,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "event_time_ms": event_ms if isinstance(event_ms, (int, float)) else None,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "latency_ms": latency_ms,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "frame_bytes": frame_bytes,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  except Exception:
Â  Â  Â  Â  Â  Â  Â  Â  pass
Â  Â  Â  Â  Â  Â  messages.append(self._normalize_payload(data))
Â  Â  Â  Â  stream.on("message", _on_message)
Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  await asyncio.sleep(self.ws_capture_seconds)
Â  Â  Â  Â  Â  Â  await stream.unsubscribe()
Â  Â  Â  Â  finally:
Â  Â  Â  Â  Â  Â  await connection.close_connection(close_session=True)
Â  Â  Â  Â  self.logger.info(
Â  Â  Â  Â  Â  Â  (
Â  Â  Â  Â  Â  Â  Â  Â  "[green]SPOT[/] rolling_window_ticker captured %d frames "
Â  Â  Â  Â  Â  Â  Â  Â  f"(window: {self.ws_window_size_name})"
Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  if RICH_AVAILABLE
Â  Â  Â  Â  Â  Â  else "SPOT rolling_window_ticker captured %d frames (window: %s)"
Â  Â  Â  Â  Â  Â  ,
Â  Â  Â  Â  Â  Â  len(messages),
Â  Â  Â  Â  Â  Â  self.ws_window_size_name,
Â  Â  Â  Â  )
Â  Â  Â  Â  return messages
Â  Â  def collect_spot_websocket(self) -> None:
Â  Â  Â  Â  self.ws_results["rolling_window_ticker"] = asyncio.run(
Â  Â  Â  Â  Â  Â  self._collect_spot_rolling_window()
Â  Â  Â  Â  )
Â  Â  # ------------------------------------------------------------------ #
Â  Â  # Persistence Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â #
Â  Â  # ------------------------------------------------------------------ #
Â  Â  def _json_default(self, obj: Any) -> Union[str, float]:
Â  Â  Â  Â  if isinstance(obj, (datetime, pd.Timestamp)):
Â  Â  Â  Â  Â  Â  return obj.isoformat()
Â  Â  Â  Â  if isinstance(obj, Decimal):
Â  Â  Â  Â  Â  Â  return float(obj)
Â  Â  Â  Â  if hasattr(obj, "__dict__"):
Â  Â  Â  Â  Â  Â  return self._normalize_payload(obj.__dict__)
Â  Â  Â  Â  return str(obj)
Â  Â  def _write_json(self, path: Path, payload: Any) -> None:
Â  Â  Â  Â  meta_wrapped = {
Â  Â  Â  Â  Â  Â  "retrieved_at": datetime.utcnow().isoformat(),
Â  Â  Â  Â  Â  Â  "payload": self._normalize_payload(payload),
Â  Â  Â  Â  }
Â  Â  Â  Â  with path.open("w", encoding="utf-8") as fh:
Â  Â  Â  Â  Â  Â  json.dump(meta_wrapped, fh, indent=2, default=self._json_default)
Â  Â  def persist_payloads(self) -> None:
Â  Â  Â  Â  for key, data in self.spot_results.items():
Â  Â  Â  Â  Â  Â  self._write_json(self.output_dir / "spot" / f"{key}.json", data)
Â  Â  Â  Â  for key, data in self.futures_results.items():
Â  Â  Â  Â  Â  Â  self._write_json(self.output_dir / "futures" / f"{key}.json", data)
Â  Â  Â  Â  for key, data in self.ws_results.items():
Â  Â  Â  Â  Â  Â  self._write_json(self.output_dir / "spot" / "websocket" / f"{key}.json", data)
Â  Â  Â  Â  message = (
Â  Â  Â  Â  Â  Â  f"[green]ðŸ—‚ï¸ Persisted payloads â†’[/] {self.output_dir.resolve()}"
Â  Â  Â  Â  Â  Â  if RICH_AVAILABLE
Â  Â  Â  Â  Â  Â  else f"Payloads persisted to {self.output_dir.resolve()}"
Â  Â  Â  Â  )
Â  Â  Â  Â  self.logger.info(message)
Â  Â  # ------------------------------------------------------------------ #
Â  Â  # Data preparation for analysis Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â #
Â  Â  # ------------------------------------------------------------------ #
Â  Â  @staticmethod
Â  Â  def _prepare_kline_df(raw: Any, module_label: str) -> pd.DataFrame:
Â  Â  Â  Â  if not raw:
Â  Â  Â  Â  Â  Â  return pd.DataFrame()
Â  Â  Â  Â  columns = [
Â  Â  Â  Â  Â  Â  "open_time",
Â  Â  Â  Â  Â  Â  "open",
Â  Â  Â  Â  Â  Â  "high",
Â  Â  Â  Â  Â  Â  "low",
Â  Â  Â  Â  Â  Â  "close",
Â  Â  Â  Â  Â  Â  "volume",
Â  Â  Â  Â  Â  Â  "close_time",
Â  Â  Â  Â  Â  Â  "quote_asset_volume",
Â  Â  Â  Â  Â  Â  "number_trades",
Â  Â  Â  Â  Â  Â  "taker_buy_base_volume",
Â  Â  Â  Â  Â  Â  "taker_buy_quote_volume",
Â  Â  Â  Â  Â  Â  "ignore",
Â  Â  Â  Â  ]
Â  Â  Â  Â  df = pd.DataFrame(raw, columns=columns)
Â  Â  Â  Â  df["open_time"] = pd.to_datetime(df["open_time"], unit="ms", utc=True)
Â  Â  Â  Â  df["close_time"] = pd.to_datetime(df["close_time"], unit="ms", utc=True)
Â  Â  Â  Â  numeric_cols = [
Â  Â  Â  Â  Â  Â  "open",
Â  Â  Â  Â  Â  Â  "high",
Â  Â  Â  Â  Â  Â  "low",
Â  Â  Â  Â  Â  Â  "close",
Â  Â  Â  Â  Â  Â  "volume",
Â  Â  Â  Â  Â  Â  "quote_asset_volume",
Â  Â  Â  Â  Â  Â  "taker_buy_base_volume",
Â  Â  Â  Â  Â  Â  "taker_buy_quote_volume",
Â  Â  Â  Â  ]
Â  Â  Â  Â  df[numeric_cols] = df[numeric_cols].astype(float)
Â  Â  Â  Â  df["module"] = module_label
Â  Â  Â  Â  return df
Â  Â  @staticmethod
Â  Â  def _prepare_funding_df(raw: Any) -> pd.DataFrame:
Â  Â  Â  Â  if not raw:
Â  Â  Â  Â  Â  Â  return pd.DataFrame()
Â  Â  Â  Â  df = pd.DataFrame(raw)
Â  Â  Â  Â  if "funding_time" in df.columns:
Â  Â  Â  Â  Â  Â  df["funding_time"] = pd.to_datetime(df["funding_time"], unit="ms", utc=True)
Â  Â  Â  Â  if "funding_rate" in df.columns:
Â  Â  Â  Â  Â  Â  df["funding_rate"] = df["funding_rate"].astype(float)
Â  Â  Â  Â  if "mark_price" in df.columns:
Â  Â  Â  Â  Â  Â  df["mark_price"] = df["mark_price"].astype(float)
Â  Â  Â  Â  return df.sort_values("funding_time")
Â  Â  @staticmethod
Â  Â  def _prepare_open_interest_df(raw: Any) -> pd.DataFrame:
Â  Â  Â  Â  if not raw:
Â  Â  Â  Â  Â  Â  return pd.DataFrame()
Â  Â  Â  Â  df = pd.DataFrame(raw)
Â  Â  Â  Â  if "timestamp" in df.columns:
Â  Â  Â  Â  Â  Â  df["timestamp"] = pd.to_datetime(df["timestamp"], unit="ms", utc=True)
Â  Â  Â  Â  for col in ("sumOpenInterest", "sumOpenInterestValue"):
Â  Â  Â  Â  Â  Â  if col in df.columns:
Â  Â  Â  Â  Â  Â  Â  Â  df[col] = df[col].astype(float)
Â  Â  Â  Â  return df.sort_values("timestamp")
Â  Â  @staticmethod
Â  Â  def _prepare_ws_df(raw: Any) -> pd.DataFrame:
Â  Â  Â  Â  if not raw:
Â  Â  Â  Â  Â  Â  return pd.DataFrame()
Â  Â  Â  Â  df = pd.json_normalize(raw)
Â  Â  Â  Â  if "E" in df.columns:
Â  Â  Â  Â  Â  Â  df["event_time"] = pd.to_datetime(df["E"], unit="ms", utc=True)
Â  Â  Â  Â  elif "event_time" in df.columns:
Â  Â  Â  Â  Â  Â  df["event_time"] = pd.to_datetime(df["event_time"], utc=True)
Â  Â  Â  Â  return df
Â  Â  @staticmethod
Â  Â  def _limit_rows(df: pd.DataFrame, max_rows: int = 720) -> pd.DataFrame:
Â  Â  Â  Â  if df.empty or len(df) <= max_rows:
Â  Â  Â  Â  Â  Â  return df
Â  Â  Â  Â  return df.tail(max_rows).copy()
Â  Â  @staticmethod
Â  Â  def _augment_kline_features(df: pd.DataFrame) -> pd.DataFrame:
Â  Â  Â  Â  if df.empty:
Â  Â  Â  Â  Â  Â  return df
Â  Â  Â  Â  df = df.sort_values("open_time").reset_index(drop=True).copy()
Â  Â  Â  Â  closes = df["close"]
Â  Â  Â  Â  volumes = df["volume"]
Â  Â  Â  Â  df["SMA_20"] = closes.rolling(window=20, min_periods=1).mean()
Â  Â  Â  Â  df["EMA_21"] = closes.ewm(span=21, adjust=False, min_periods=1).mean()
Â  Â  Â  Â  df["EMA_55"] = closes.ewm(span=55, adjust=False, min_periods=1).mean()
Â  Â  Â  Â  cumulative_vp = (closes * volumes).cumsum()
Â  Â  Â  Â  cumulative_vol = volumes.replace(0, np.nan).cumsum()
Â  Â  Â  Â  df["VWAP"] = cumulative_vp / cumulative_vol
Â  Â  Â  Â  delta = closes.diff()
Â  Â  Â  Â  up = delta.clip(lower=0)
Â  Â  Â  Â  down = (-delta).clip(lower=0)
Â  Â  Â  Â  roll_up = up.ewm(alpha=1 / 14, adjust=False, min_periods=14).mean()
Â  Â  Â  Â  roll_down = down.ewm(alpha=1 / 14, adjust=False, min_periods=14).mean()
Â  Â  Â  Â  rs = roll_up / roll_down.replace(0, np.nan)
Â  Â  Â  Â  df["RSI_14"] = 100 - (100 / (1 + rs))
Â  Â  Â  Â  ema12 = closes.ewm(span=12, adjust=False, min_periods=1).mean()
Â  Â  Â  Â  ema26 = closes.ewm(span=26, adjust=False, min_periods=1).mean()
Â  Â  Â  Â  df["MACD"] = ema12 - ema26
Â  Â  Â  Â  df["MACD_signal"] = df["MACD"].ewm(span=9, adjust=False, min_periods=1).mean()
Â  Â  Â  Â  df["MACD_hist"] = df["MACD"] - df["MACD_signal"]
Â  Â  Â  Â  df["log_return"] = np.log(closes).diff()
Â  Â  Â  Â  df["pct_change"] = closes.pct_change()
Â  Â  Â  Â  df["volume_ma20"] = volumes.rolling(20, min_periods=1).mean()
Â  Â  Â  Â  return df
Â  Â  @staticmethod
Â  Â  def _compute_volume_colors(df: pd.DataFrame) -> List[str]:
Â  Â  Â  Â  up_color = "#26A69A"
Â  Â  Â  Â  down_color = "#EF5350"
Â  Â  Â  Â  return [
Â  Â  Â  Â  Â  Â  up_color if close >= open_ else down_color
Â  Â  Â  Â  Â  Â  for open_, close in zip(df["open"], df["close"])
Â  Â  Â  Â  ]
Â  Â  @staticmethod
Â  Â  def _make_mpf_style() -> mpf.Style:
Â  Â  Â  Â  market_colors = mpf.make_marketcolors(
Â  Â  Â  Â  Â  Â  up="#26A69A",
Â  Â  Â  Â  Â  Â  down="#EF5350",
Â  Â  Â  Â  Â  Â  edge="inherit",
Â  Â  Â  Â  Â  Â  wick="inherit",
Â  Â  Â  Â  Â  Â  volume="inherit",
Â  Â  Â  Â  )
Â  Â  Â  Â  return mpf.make_mpf_style(
Â  Â  Â  Â  Â  Â  base_mpf_style="yahoo",
Â  Â  Â  Â  Â  Â  marketcolors=market_colors,
Â  Â  Â  Â  Â  Â  facecolor="#f8f9fb",
Â  Â  Â  Â  Â  Â  edgecolor="#CFD8DC",
Â  Â  Â  Â  Â  Â  gridcolor="#dfe4ea",
Â  Â  Â  Â  Â  Â  gridstyle="--",
Â  Â  Â  Â  Â  Â  mavcolors=["#1E88E5", "#D81B60", "#F9A825"],
Â  Â  Â  Â  )
Â  Â  # ------------------------------------------------------------------ #
Â  Â  # Visual analytics Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  #
Â  Â  # ------------------------------------------------------------------ #
Â  Â  def generate_visualisations(self) -> None:
Â  Â  Â  Â  if not MPLFINANCE_AVAILABLE:
Â  Â  Â  Â  Â  Â  raise RuntimeError(
Â  Â  Â  Â  Â  Â  Â  Â  "mplfinance is required for advanced visualisations. Install it via `pip install mplfinance`."
Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  self._emit_section_header("Generating visual analytics", style="bold yellow", emoji="ðŸ“Š")
Â  Â  Â  Â  spot_kline_df = self._prepare_kline_df(self.spot_results.get("klines"), "Spot")
Â  Â  Â  Â  futures_kline_df = self._prepare_kline_df(self.futures_results.get("klines"), "USDS Futures")
Â  Â  Â  Â  spot_kline_df = self._augment_kline_features(spot_kline_df)
Â  Â  Â  Â  futures_kline_df = self._augment_kline_features(futures_kline_df)
Â  Â  Â  Â  funding_df = self._prepare_funding_df(self.futures_results.get("funding_rate_history"))
Â  Â  Â  Â  open_interest_df = self._prepare_open_interest_df(self.futures_results.get("open_interest_hist"))
Â  Â  Â  Â  ws_df = self._prepare_ws_df(self.ws_results.get("rolling_window_ticker"))
Â  Â  Â  Â  self._plot_spot_candlestick_dashboard(spot_kline_df)
Â  Â  Â  Â  self._plot_futures_candlestick_dashboard(futures_kline_df, open_interest_df)
Â  Â  Â  Â  self._plot_basis_diagnostics(spot_kline_df, futures_kline_df, funding_df)
Â  Â  Â  Â  self._plot_multi_timescale_correlation(spot_kline_df, futures_kline_df)
Â  Â  Â  Â  self._plot_websocket_microstructure(ws_df)
Â  Â  def _plot_spot_candlestick_dashboard(self, spot_df: pd.DataFrame) -> None:
Â  Â  Â  Â  if spot_df.empty:
Â  Â  Â  Â  Â  Â  self.logger.warning("Skipping spot candlestick dashboard (no kline data).")
Â  Â  Â  Â  Â  Â  return
Â  Â  Â  Â  trimmed = self._limit_rows(spot_df, 900)
Â  Â  Â  Â  spot_idx = trimmed.set_index("open_time")
Â  Â  Â  Â  mpf_data = spot_idx[["open", "high", "low", "close", "volume"]].copy()
Â  Â  Â  Â  mpf_data.columns = ["Open", "High", "Low", "Close", "Volume"]
Â  Â  Â  Â  volume_colors = self._compute_volume_colors(trimmed)
Â  Â  Â  Â  addplots = [
Â  Â  Â  Â  Â  Â  mpf.make_addplot(spot_idx["SMA_20"], panel=0, color="#1E88E5", width=1.15),
Â  Â  Â  Â  Â  Â  mpf.make_addplot(spot_idx["EMA_55"], panel=0, color="#D81B60", linestyle="--", width=1.0),
Â  Â  Â  Â  Â  Â  mpf.make_addplot(spot_idx["VWAP"], panel=0, color="#F9A825", linestyle="-", width=1.0),
Â  Â  Â  Â  Â  Â  mpf.make_addplot(spot_idx["RSI_14"], panel=1, color="#00897B", width=1.1),
Â  Â  Â  Â  Â  Â  mpf.make_addplot(
Â  Â  Â  Â  Â  Â  Â  Â  spot_idx["volume"],
Â  Â  Â  Â  Â  Â  Â  Â  panel=2,
Â  Â  Â  Â  Â  Â  Â  Â  type="bar",
Â  Â  Â  Â  Â  Â  Â  Â  color=volume_colors,
Â  Â  Â  Â  Â  Â  Â  Â  alpha=0.45,
Â  Â  Â  Â  Â  Â  Â  Â  secondary_y=False,
Â  Â  Â  Â  Â  Â  ),
Â  Â  Â  Â  Â  Â  mpf.make_addplot(
Â  Â  Â  Â  Â  Â  Â  Â  spot_idx["volume_ma20"],
Â  Â  Â  Â  Â  Â  Â  Â  panel=2,
Â  Â  Â  Â  Â  Â  Â  Â  color="#4DD0E1",
Â  Â  Â  Â  Â  Â  Â  Â  width=1.0,
Â  Â  Â  Â  Â  Â  Â  Â  linestyle="--",
Â  Â  Â  Â  Â  Â  ),
Â  Â  Â  Â  ]
Â  Â  Â  Â  fig, axes = mpf.plot(
Â  Â  Â  Â  Â  Â  mpf_data,
Â  Â  Â  Â  Â  Â  type="candle",
Â  Â  Â  Â  Â  Â  style=self._make_mpf_style(),
Â  Â  Â  Â  Â  Â  addplot=addplots,
Â  Â  Â  Â  Â  Â  panel_ratios=(14, 4, 5),
Â  Â  Â  Â  Â  Â  figratio=(16, 9),
Â  Â  Â  Â  Â  Â  figscale=1.15,
Â  Â  Â  Â  Â  Â  xrotation=0,
Â  Â  Â  Â  Â  Â  update_width_config=dict(candle_linewidth=0.8, candle_width=0.6),
Â  Â  Â  Â  Â  Â  returnfig=True,
Â  Â  Â  Â  )
Â  Â  Â  Â  price_ax = axes[0]
Â  Â  Â  Â  rsi_ax = axes[1]
Â  Â  Â  Â  volume_ax = axes[2]
Â  Â  Â  Â  price_ax.set_ylabel("Price (USDT)")
Â  Â  Â  Â  price_ax.set_title(
Â  Â  Â  Â  Â  Â  f"{self.spot_symbol} Spot Candlestick Dashboard\n"
Â  Â  Â  Â  Â  Â  "1-minute candles â€¢ SMA20 / EMA55 / VWAP overlays",
Â  Â  Â  Â  Â  Â  loc="left",
Â  Â  Â  Â  Â  Â  fontsize=12,
Â  Â  Â  Â  )
Â  Â  Â  Â  rsi_ax.set_ylabel("RSI (14)")
Â  Â  Â  Â  rsi_ax.axhline(70, color="#EF5350", linestyle="--", linewidth=0.8, alpha=0.7)
Â  Â  Â  Â  rsi_ax.axhline(30, color="#26A69A", linestyle="--", linewidth=0.8, alpha=0.7)
Â  Â  Â  Â  rsi_ax.set_ylim(0, 100)
Â  Â  Â  Â  volume_ax.set_ylabel("Volume")
Â  Â  Â  Â  volume_ax.yaxis.set_major_formatter(mticker.FuncFormatter(lambda y, _: f"{y/1_000:.0f}K"))
Â  Â  Â  Â  self._save_figure(fig, "fig_spot_candlestick_dashboard.png")
Â  Â  def _plot_futures_candlestick_dashboard(
Â  Â  Â  Â  self,
Â  Â  Â  Â  futures_df: pd.DataFrame,
Â  Â  Â  Â  open_interest_df: pd.DataFrame,
Â  Â  ) -> None:
Â  Â  Â  Â  if futures_df.empty:
Â  Â  Â  Â  Â  Â  self.logger.warning("Skipping futures candlestick dashboard (no kline data).")
Â  Â  Â  Â  Â  Â  return
Â  Â  Â  Â  trimmed = self._limit_rows(futures_df, 900).copy()
Â  Â  Â  Â  oi_series = pd.Series(dtype=float)
Â  Â  Â  Â  if not open_interest_df.empty and "timestamp" in open_interest_df and "sumOpenInterest" in open_interest_df:
Â  Â  Â  Â  Â  Â  oi_series = (
Â  Â  Â  Â  Â  Â  Â  Â  open_interest_df[["timestamp", "sumOpenInterest"]]
Â  Â  Â  Â  Â  Â  Â  Â  .dropna()
Â  Â  Â  Â  Â  Â  Â  Â  .sort_values("timestamp")
Â  Â  Â  Â  Â  Â  Â  Â  .set_index("timestamp")["sumOpenInterest"]
Â  Â  Â  Â  Â  Â  Â  Â  .astype(float)
Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  aligned_index = trimmed["open_time"]
Â  Â  Â  Â  Â  Â  aligned_oi = (
Â  Â  Â  Â  Â  Â  Â  Â  oi_series.reindex(aligned_index, method="ffill")
Â  Â  Â  Â  Â  Â  Â  Â  .fillna(method="bfill")
Â  Â  Â  Â  Â  Â  Â  Â  .to_numpy()
Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  trimmed["open_interest"] = aligned_oi
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  trimmed["open_interest"] = np.nan
Â  Â  Â  Â  futures_idx = trimmed.set_index("open_time")
Â  Â  Â  Â  mpf_data = futures_idx[["open", "high", "low", "close", "volume"]].copy()
Â  Â  Â  Â  mpf_data.columns = ["Open", "High", "Low", "Close", "Volume"]
Â  Â  Â  Â  volume_colors = self._compute_volume_colors(trimmed)
Â  Â  Â  Â  macd_hist = futures_idx["MACD_hist"].fillna(0.0)
Â  Â  Â  Â  macd_hist_colors = ["#26A69A" if val >= 0 else "#EF5350" for val in macd_hist]
Â  Â  Â  Â  include_oi = not trimmed["open_interest"].isna().all()
Â  Â  Â  Â  macd_panel = 1
Â  Â  Â  Â  if include_oi:
Â  Â  Â  Â  Â  Â  oi_panel = 2
Â  Â  Â  Â  Â  Â  volume_panel = 3
Â  Â  Â  Â  Â  Â  panel_ratios = (14, 4, 5, 5)
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  volume_panel = 2
Â  Â  Â  Â  Â  Â  panel_ratios = (14, 4, 5)
Â  Â  Â  Â  addplots = [
Â  Â  Â  Â  Â  Â  mpf.make_addplot(futures_idx["EMA_21"], panel=0, color="#009688", width=1.1),
Â  Â  Â  Â  Â  Â  mpf.make_addplot(futures_idx["EMA_55"], panel=0, color="#5E35B1", linestyle="--", width=1.0),
Â  Â  Â  Â  Â  Â  mpf.make_addplot(futures_idx["VWAP"], panel=0, color="#FFA726", width=1.0),
Â  Â  Â  Â  Â  Â  mpf.make_addplot(macd_hist, panel=macd_panel, type="bar", color=macd_hist_colors, alpha=0.45),
Â  Â  Â  Â  Â  Â  mpf.make_addplot(futures_idx["MACD"], panel=macd_panel, color="#42A5F5", width=1.1),
Â  Â  Â  Â  Â  Â  mpf.make_addplot(futures_idx["MACD_signal"], panel=macd_panel, color="#EF6C00", linestyle="--", width=1.0),
Â  Â  Â  Â  ]
Â  Â  Â  Â  if include_oi:
Â  Â  Â  Â  Â  Â  addplots.append(
Â  Â  Â  Â  Â  Â  Â  Â  mpf.make_addplot(
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  futures_idx["open_interest"],
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  panel=oi_panel,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  color="#7E57C2",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  width=1.1,
Â  Â  Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  addplots.append(
Â  Â  Â  Â  Â  Â  mpf.make_addplot(
Â  Â  Â  Â  Â  Â  Â  Â  futures_idx["volume"],
Â  Â  Â  Â  Â  Â  Â  Â  panel=volume_panel,
Â  Â  Â  Â  Â  Â  Â  Â  type="bar",
Â  Â  Â  Â  Â  Â  Â  Â  color=volume_colors,
Â  Â  Â  Â  Â  Â  Â  Â  alpha=0.45,
Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  )
Â  Â  Â  Â  addplots.append(
Â  Â  Â  Â  Â  Â  mpf.make_addplot(
Â  Â  Â  Â  Â  Â  Â  Â  futures_idx["volume_ma20"],
Â  Â  Â  Â  Â  Â  Â  Â  panel=volume_panel,
Â  Â  Â  Â  Â  Â  Â  Â  color="#29B6F6",
Â  Â  Â  Â  Â  Â  Â  Â  linestyle="--",
Â  Â  Â  Â  Â  Â  Â  Â  width=1.0,
Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  )
Â  Â  Â  Â  fig, axes = mpf.plot(
Â  Â  Â  Â  Â  Â  mpf_data,
Â  Â  Â  Â  Â  Â  type="candle",
Â  Â  Â  Â  Â  Â  style=self._make_mpf_style(),
Â  Â  Â  Â  Â  Â  addplot=addplots,
Â  Â  Â  Â  Â  Â  panel_ratios=panel_ratios,
Â  Â  Â  Â  Â  Â  figratio=(16, 10),
Â  Â  Â  Â  Â  Â  figscale=1.18,
Â  Â  Â  Â  Â  Â  xrotation=0,
Â  Â  Â  Â  Â  Â  update_width_config=dict(candle_linewidth=0.8, candle_width=0.6),
Â  Â  Â  Â  Â  Â  returnfig=True,
Â  Â  Â  Â  )
Â  Â  Â  Â  price_ax = axes[0]
Â  Â  Â  Â  macd_ax = axes[1]
Â  Â  Â  Â  if include_oi:
Â  Â  Â  Â  Â  Â  oi_ax = axes[2]
Â  Â  Â  Â  Â  Â  volume_ax = axes[3]
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  volume_ax = axes[2]
Â  Â  Â  Â  Â  Â  oi_ax = None
Â  Â  Â  Â  price_ax.set_ylabel("Price (USDT)")
Â  Â  Â  Â  price_ax.set_title(
Â  Â  Â  Â  Â  Â  f"{self.futures_symbol} Perpetual Futures Structure\n"
Â  Â  Â  Â  Â  Â  "1-minute candles â€¢ EMA21/EMA55/VWAP â€¢ MACD â€¢ Open Interest",
Â  Â  Â  Â  Â  Â  loc="left",
Â  Â  Â  Â  Â  Â  fontsize=12,
Â  Â  Â  Â  )
Â  Â  Â  Â  macd_ax.axhline(0, color="#90A4AE", linestyle="--", linewidth=0.8, alpha=0.6)
Â  Â  Â  Â  macd_ax.set_ylabel("MACD")
Â  Â  Â  Â  if oi_ax is not None:
Â  Â  Â  Â  Â  Â  oi_ax.set_ylabel("Open Interest")
Â  Â  Â  Â  Â  Â  oi_ax.yaxis.set_major_formatter(
Â  Â  Â  Â  Â  Â  Â  Â  mticker.FuncFormatter(lambda y, _: f"{y/1_000:.0f}K")
Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  volume_ax.set_ylabel("Volume")
Â  Â  Â  Â  volume_ax.yaxis.set_major_formatter(mticker.FuncFormatter(lambda y, _: f"{y/1_000:.0f}K"))
Â  Â  Â  Â  self._save_figure(fig, "fig_futures_candlestick_dashboard.png")
Â  Â  def _plot_basis_diagnostics(
Â  Â  Â  Â  self,
Â  Â  Â  Â  spot_df: pd.DataFrame,
Â  Â  Â  Â  futures_df: pd.DataFrame,
Â  Â  Â  Â  funding_df: pd.DataFrame,
Â  Â  ) -> None:
Â  Â  Â  Â  if spot_df.empty or futures_df.empty:
Â  Â  Â  Â  Â  Â  self.logger.warning("Skipping basis diagnostics (insufficient spot/futures klines).")
Â  Â  Â  Â  Â  Â  return
Â  Â  Â  Â  merged = pd.merge(
Â  Â  Â  Â  Â  Â  spot_df[["open_time", "close"]],
Â  Â  Â  Â  Â  Â  futures_df[["open_time", "close"]],
Â  Â  Â  Â  Â  Â  on="open_time",
Â  Â  Â  Â  Â  Â  suffixes=("_spot", "_fut"),
Â  Â  Â  Â  ).sort_values("open_time")
Â  Â  Â  Â  if merged.empty:
Â  Â  Â  Â  Â  Â  self.logger.warning("Skipping basis diagnostics (no overlapping candles).")
Â  Â  Â  Â  Â  Â  return
Â  Â  Â  Â  merged["basis_usdt"] = merged["close_fut"] - merged["close_spot"]
Â  Â  Â  Â  merged["basis_bps"] = (merged["basis_usdt"] / merged["close_spot"]) * 10_000
Â  Â  Â  Â  merged["premium_pct"] = (merged["close_fut"] / merged["close_spot"] - 1) * 100
Â  Â  Â  Â  merged["rolling_basis_bps"] = merged["basis_bps"].rolling(60, min_periods=1).mean()
Â  Â  Â  Â  basis_resampled = (
Â  Â  Â  Â  Â  Â  merged.set_index("open_time")["basis_bps"].resample("15T").mean().dropna()
Â  Â  Â  Â  )
Â  Â  Â  Â  premium_resampled = (
Â  Â  Â  Â  Â  Â  merged.set_index("open_time")["premium_pct"].resample("15T").mean().dropna()
Â  Â  Â  Â  )
Â  Â  Â  Â  include_funding = not funding_df.empty
Â  Â  Â  Â  nrows = 3 if include_funding else 2
Â  Â  Â  Â  fig, axes = plt.subplots(
Â  Â  Â  Â  Â  Â  nrows=nrows,
Â  Â  Â  Â  Â  Â  ncols=1,
Â  Â  Â  Â  Â  Â  sharex=True,
Â  Â  Â  Â  Â  Â  figsize=(12*2, 9*2 if include_funding else 7.2*2),
Â  Â  Â  Â  )
Â  Â  Â  Â  ax0 = axes[0]
Â  Â  Â  Â  ax0.plot(
Â  Â  Â  Â  Â  Â  merged["open_time"],
Â  Â  Â  Â  Â  Â  merged["basis_bps"],
Â  Â  Â  Â  Â  Â  color="#3949AB",
Â  Â  Â  Â  Â  Â  linewidth=1.1,
Â  Â  Â  Â  Â  Â  label="Basis (bps)",
Â  Â  Â  Â  )
Â  Â  Â  Â  ax0.plot(
Â  Â  Â  Â  Â  Â  merged["open_time"],
Â  Â  Â  Â  Â  Â  merged["rolling_basis_bps"],
Â  Â  Â  Â  Â  Â  color="#F4511E",
Â  Â  Â  Â  Â  Â  linewidth=1.2,
Â  Â  Â  Â  Â  Â  linestyle="--",
Â  Â  Â  Â  Â  Â  label="Basis 60m Avg",
Â  Â  Â  Â  )
Â  Â  Â  Â  ax0.fill_between(
Â  Â  Â  Â  Â  Â  merged["open_time"],
Â  Â  Â  Â  Â  Â  0,
Â  Â  Â  Â  Â  Â  merged["basis_bps"],
Â  Â  Â  Â  Â  Â  where=(merged["basis_bps"] >= 0),
Â  Â  Â  Â  Â  Â  color="#8E24AA",
Â  Â  Â  Â  Â  Â  alpha=0.15,
Â  Â  Â  Â  )
Â  Â  Â  Â  ax0.fill_between(
Â  Â  Â  Â  Â  Â  merged["open_time"],
Â  Â  Â  Â  Â  Â  0,
Â  Â  Â  Â  Â  Â  merged["basis_bps"],
Â  Â  Â  Â  Â  Â  where=(merged["basis_bps"] < 0),
Â  Â  Â  Â  Â  Â  color="#039BE5",
Â  Â  Â  Â  Â  Â  alpha=0.15,
Â  Â  Â  Â  )
Â  Â  Â  Â  ax0.axhline(0, color="#90A4AE", linestyle="--", linewidth=0.8, alpha=0.6)
Â  Â  Â  Â  ax0.set_ylabel("Basis (bps)")
Â  Â  Â  Â  ax0.legend(loc="upper left", frameon=False)
Â  Â  Â  Â  self._apply_academic_style(ax0)
Â  Â  Â  Â  ax1 = axes[1]
Â  Â  Â  Â  ax1.plot(
Â  Â  Â  Â  Â  Â  basis_resampled.index,
Â  Â  Â  Â  Â  Â  basis_resampled.values,
Â  Â  Â  Â  Â  Â  color="#6D4C41",
Â  Â  Â  Â  Â  Â  linewidth=1.1,
Â  Â  Â  Â  Â  Â  label="Basis (15m mean)",
Â  Â  Â  Â  )
Â  Â  Â  Â  ax1.plot(
Â  Â  Â  Â  Â  Â  premium_resampled.index,
Â  Â  Â  Â  Â  Â  premium_resampled.values * 100,
Â  Â  Â  Â  Â  Â  color="#00796B",
Â  Â  Â  Â  Â  Â  linewidth=1.0,
Â  Â  Â  Â  Â  Â  linestyle="--",
Â  Â  Â  Â  Â  Â  label="Premium (% Ã—100)",
Â  Â  Â  Â  )
Â  Â  Â  Â  ax1.set_ylabel("Medium-term Basis")
Â  Â  Â  Â  ax1.legend(loc="upper left", frameon=False)
Â  Â  Â  Â  self._apply_academic_style(ax1)
Â  Â  Â  Â  if include_funding:
Â  Â  Â  Â  Â  Â  ax2 = axes[2]
Â  Â  Â  Â  Â  Â  funding_df = funding_df.dropna(subset=["funding_time", "funding_rate"])
Â  Â  Â  Â  Â  Â  funding_df["funding_bps"] = funding_df["funding_rate"] * 10_000
Â  Â  Â  Â  Â  Â  ax2.bar(
Â  Â  Â  Â  Â  Â  Â  Â  funding_df["funding_time"],
Â  Â  Â  Â  Â  Â  Â  Â  funding_df["funding_bps"],
Â  Â  Â  Â  Â  Â  Â  Â  color=np.where(funding_df["funding_bps"] >= 0, "#26A69A", "#EF5350"),
Â  Â  Â  Â  Â  Â  Â  Â  width=0.02,
Â  Â  Â  Â  Â  Â  Â  Â  alpha=0.8,
Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  ax2.axhline(0, color="#90A4AE", linestyle="--", linewidth=0.8, alpha=0.6)
Â  Â  Â  Â  Â  Â  ax2.set_ylabel("Funding (bps)")
Â  Â  Â  Â  Â  Â  self._apply_academic_style(ax2)
Â  Â  Â  Â  axes[-1].set_xlabel("Timestamp (UTC)")
Â  Â  Â  Â  self._format_datetime_axis(axes[-1])
Â  Â  Â  Â  axes[0].set_title(
Â  Â  Â  Â  Â  Â  f"{self.spot_symbol} vs {self.futures_symbol} Basis Diagnostics",
Â  Â  Â  Â  Â  Â  loc="left",
Â  Â  Â  Â  )
Â  Â  Â  Â  self._save_figure(fig, "fig_basis_diagnostics.png")
Â  Â  def _plot_multi_timescale_correlation(
Â  Â  Â  Â  self, spot_df: pd.DataFrame, futures_df: pd.DataFrame
Â  Â  ) -> None:
Â  Â  Â  Â  if spot_df.empty or futures_df.empty:
Â  Â  Â  Â  Â  Â  self.logger.warning("Skipping correlation analytics (insufficient data).")
Â  Â  Â  Â  Â  Â  return
Â  Â  Â  Â  spot_series = spot_df.set_index("open_time")["close"]
Â  Â  Â  Â  futures_series = futures_df.set_index("open_time")["close"]
Â  Â  Â  Â  resolutions = {
Â  Â  Â  Â  Â  Â  "1 Minute": "1T",
Â  Â  Â  Â  Â  Â  "5 Minute": "5T",
Â  Â  Â  Â  Â  Â  "15 Minute": "15T",
Â  Â  Â  Â  Â  Â  "1 Hour": "1H",
Â  Â  Â  Â  }
Â  Â  Â  Â  records: List[Dict[str, float]] = []
Â  Â  Â  Â  for label, rule in resolutions.items():
Â  Â  Â  Â  Â  Â  spot_resampled = spot_series.resample(rule).last().dropna()
Â  Â  Â  Â  Â  Â  fut_resampled = futures_series.resample(rule).last().dropna()
Â  Â  Â  Â  Â  Â  aligned = pd.concat([spot_resampled, fut_resampled], axis=1).dropna()
Â  Â  Â  Â  Â  Â  if aligned.empty:
Â  Â  Â  Â  Â  Â  Â  Â  continue
Â  Â  Â  Â  Â  Â  aligned.columns = ["spot", "futures"]
Â  Â  Â  Â  Â  Â  log_returns = np.log(aligned).diff().dropna()
Â  Â  Â  Â  Â  Â  if log_returns.empty:
Â  Â  Â  Â  Â  Â  Â  Â  continue
Â  Â  Â  Â  Â  Â  corr = log_returns["spot"].corr(log_returns["futures"])
Â  Â  Â  Â  Â  Â  beta = (
Â  Â  Â  Â  Â  Â  Â  Â  log_returns["futures"].cov(log_returns["spot"])
Â  Â  Â  Â  Â  Â  Â  Â  / log_returns["spot"].var()
Â  Â  Â  Â  Â  Â  Â  Â  if log_returns["spot"].var() > 0
Â  Â  Â  Â  Â  Â  Â  Â  else np.nan
Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  vol_spot = log_returns["spot"].std() * np.sqrt(365 * (24 * 60 / pd.Timedelta(rule).seconds))
Â  Â  Â  Â  Â  Â  vol_fut = log_returns["futures"].std() * np.sqrt(365 * (24 * 60 / pd.Timedelta(rule).seconds))
Â  Â  Â  Â  Â  Â  records.append(
Â  Â  Â  Â  Â  Â  Â  Â  {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Timeframe": label,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Correlation": corr,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Futures Beta": beta,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Spot Vol (ann%)": vol_spot * 100,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Futures Vol (ann%)": vol_fut * 100,
Â  Â  Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  if not records:
Â  Â  Â  Â  Â  Â  self.logger.warning("Skipping correlation analytics (no overlapping samples).")
Â  Â  Â  Â  Â  Â  return
Â  Â  Â  Â  metrics = pd.DataFrame(records).set_index("Timeframe")
Â  Â  Â  Â  fig, axes = plt.subplots(1, 2, figsize=(12*2, 4.6*2), sharey=True)
Â  Â  Â  Â  corr_ax = axes[0]
Â  Â  Â  Â  corr_ax.barh(
Â  Â  Â  Â  Â  Â  metrics.index,
Â  Â  Â  Â  Â  Â  metrics["Correlation"],
Â  Â  Â  Â  Â  Â  color="#1E88E5",
Â  Â  Â  Â  Â  Â  alpha=0.75,
Â  Â  Â  Â  )
Â  Â  Â  Â  corr_ax.set_xlim(0.8, 1.01)
Â  Â  Â  Â  corr_ax.axvline(1.0, color="#90A4AE", linestyle="--", linewidth=0.8, alpha=0.7)
Â  Â  Â  Â  corr_ax.set_xlabel("Correlation")
Â  Â  Â  Â  corr_ax.set_title("Spot â†” Futures Correlation", loc="left")
Â  Â  Â  Â  beta_ax = axes[1]
Â  Â  Â  Â  beta_ax.barh(
Â  Â  Â  Â  Â  Â  metrics.index,
Â  Â  Â  Â  Â  Â  metrics["Futures Beta"],
Â  Â  Â  Â  Â  Â  color="#F4511E",
Â  Â  Â  Â  Â  Â  alpha=0.75,
Â  Â  Â  Â  )
Â  Â  Â  Â  beta_ax.axvline(1.0, color="#90A4AE", linestyle="--", linewidth=0.8, alpha=0.7)
Â  Â  Â  Â  beta_ax.set_xlim(0.8, 1.3)
Â  Â  Â  Â  beta_ax.set_xlabel("Beta (Futures vs Spot)")
Â  Â  Â  Â  beta_ax.set_title("Dynamic Beta by Timeframe", loc="left")
Â  Â  Â  Â  for ax in axes:
Â  Â  Â  Â  Â  Â  self._apply_academic_style(ax)
Â  Â  Â  Â  Â  Â  ax.set_facecolor("#FAFAFA")
Â  Â  Â  Â  Â  Â  ax.grid(axis="x", linestyle="--", alpha=0.45)
Â  Â  Â  Â  fig.suptitle(
Â  Â  Â  Â  Â  Â  f"{self.spot_symbol}: Multi-timescale Co-movement",
Â  Â  Â  Â  Â  Â  x=0.01,
Â  Â  Â  Â  Â  Â  y=0.98,
Â  Â  Â  Â  Â  Â  ha="left",
Â  Â  Â  Â  Â  Â  fontsize=12,
Â  Â  Â  Â  Â  Â  fontweight="semibold",
Â  Â  Â  Â  )
Â  Â  Â  Â  self._save_figure(fig, "fig_timescale_correlation_beta.png")
Â  Â  def _plot_websocket_microstructure(self, ws_df: pd.DataFrame) -> None:
Â  Â  Â  Â  if ws_df.empty:
Â  Â  Â  Â  Â  Â  self.logger.warning("Skipping WebSocket microstructure plot (no frames captured).")
Â  Â  Â  Â  Â  Â  return
Â  Â  Â  Â  if "event_time" not in ws_df.columns:
Â  Â  Â  Â  Â  Â  self.logger.warning("WebSocket payload missing event timestamps; skipping visualisation.")
Â  Â  Â  Â  Â  Â  return
Â  Â  Â  Â  ws_df = ws_df.sort_values("event_time").copy()
Â  Â  Â  Â  ws_df["price"] = ws_df.get("c", ws_df.get("close", np.nan)).astype(float)
Â  Â  Â  Â  if ws_df["price"].isna().all():
Â  Â  Â  Â  Â  Â  self.logger.warning("WebSocket payload missing last price; skipping microstructure plot.")
Â  Â  Â  Â  Â  Â  return
Â  Â  Â  Â  volume_col = None
Â  Â  Â  Â  for candidate in ("v", "volume", "V", "total_volume"):
Â  Â  Â  Â  Â  Â  if candidate in ws_df.columns:
Â  Â  Â  Â  Â  Â  Â  Â  volume_col = candidate
Â  Â  Â  Â  Â  Â  Â  Â  break
Â  Â  Â  Â  if volume_col:
Â  Â  Â  Â  Â  Â  ws_df["volume"] = ws_df[volume_col].astype(float)
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  ws_df["volume"] = np.nan
Â  Â  Â  Â  ws_df["event_time"] = pd.to_datetime(ws_df["event_time"], utc=True)
Â  Â  Â  Â  ws_df["price_delta"] = ws_df["price"].diff()
Â  Â  Â  Â  ws_df.set_index("event_time", inplace=True)
Â  Â  Â  Â  include_volume = not ws_df["volume"].isna().all()
Â  Â  Â  Â  latency_records = []
Â  Â  Â  Â  if hasattr(self, "benchmark_metrics"):
Â  Â  Â  Â  Â  Â  latency_records = getattr(self, "benchmark_metrics", {}).get("ws", [])
Â  Â  Â  Â  latency_df = pd.DataFrame(latency_records)
Â  Â  Â  Â  if not latency_df.empty and "ts" in latency_df and "latency_ms" in latency_df:
Â  Â  Â  Â  Â  Â  latency_df["ts"] = pd.to_datetime(latency_df["ts"], utc=True)
Â  Â  Â  Â  Â  Â  latency_df = latency_df.dropna(subset=["latency_ms"])
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  latency_df = pd.DataFrame()
Â  Â  Â  Â  panels = 1 + (1 if include_volume else 0) + (1 if not latency_df.empty else 0)
Â  Â  Â  Â  fig_height = 3 + 2.1 * (panels - 1)
Â  Â  Â  Â  fig, axes = plt.subplots(panels, 1, sharex=True, figsize=(11.5*2, fig_height*2))
Â  Â  Â  Â  if panels == 1:
Â  Â  Â  Â  Â  Â  axes = [axes]
Â  Â  Â  Â  price_ax = axes[0]
Â  Â  Â  Â  price_ax.plot(ws_df.index, ws_df["price"], color="#1E88E5", linewidth=1.1, label="Price")
Â  Â  Â  Â  price_ax.scatter(
Â  Â  Â  Â  Â  Â  ws_df.index,
Â  Â  Â  Â  Â  Â  ws_df["price"],
Â  Â  Â  Â  Â  Â  c=np.where(ws_df["price_delta"] >= 0, "#26A69A", "#EF5350"),
Â  Â  Â  Â  Â  Â  s=10,
Â  Â  Â  Â  Â  Â  alpha=0.6,
Â  Â  Â  Â  )
Â  Â  Â  Â  price_ax.set_ylabel("Price (USDT)")
Â  Â  Â  Â  price_ax.set_title(
Â  Â  Â  Â  Â  Â  f"{self.spot_symbol} WebSocket Microstructure\n"
Â  Â  Â  Â  Â  Â  f"{len(ws_df)} frames across {self.ws_capture_seconds}s",
Â  Â  Â  Â  Â  Â  loc="left",
Â  Â  Â  Â  )
Â  Â  Â  Â  self._apply_academic_style(price_ax)
Â  Â  Â  Â  axis_idx = 1
Â  Â  Â  Â  if include_volume:
Â  Â  Â  Â  Â  Â  vol_ax = axes[axis_idx]
Â  Â  Â  Â  Â  Â  vol_colors = np.where(ws_df["price_delta"] >= 0, "#26A69A", "#EF5350")
Â  Â  Â  Â  Â  Â  vol_ax.bar(ws_df.index, ws_df["volume"], color=vol_colors, alpha=0.6)
Â  Â  Â  Â  Â  Â  vol_ax.set_ylabel("Volume")
Â  Â  Â  Â  Â  Â  vol_ax.yaxis.set_major_formatter(mticker.FuncFormatter(lambda y, _: f"{y:.2f}"))
Â  Â  Â  Â  Â  Â  self._apply_academic_style(vol_ax)
Â  Â  Â  Â  Â  Â  axis_idx += 1
Â  Â  Â  Â  if not latency_df.empty:
Â  Â  Â  Â  Â  Â  latency_ax = axes[axis_idx]
Â  Â  Â  Â  Â  Â  latency_ax.plot(
Â  Â  Â  Â  Â  Â  Â  Â  latency_df["ts"],
Â  Â  Â  Â  Â  Â  Â  Â  latency_df["latency_ms"].astype(float),
Â  Â  Â  Â  Â  Â  Â  Â  color="#F4511E",
Â  Â  Â  Â  Â  Â  Â  Â  linewidth=1.1,
Â  Â  Â  Â  Â  Â  Â  Â  marker="o",
Â  Â  Â  Â  Â  Â  Â  Â  markersize=4,
Â  Â  Â  Â  Â  Â  Â  Â  alpha=0.8,
Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  latency_ax.set_ylabel("Latency (ms)")
Â  Â  Â  Â  Â  Â  latency_ax.set_xlabel("Event time (UTC)")
Â  Â  Â  Â  Â  Â  latency_ax.grid(True, linestyle="--", linewidth=0.6, alpha=0.4)
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  axes[-1].set_xlabel("Event time (UTC)")
Â  Â  Â  Â  self._format_datetime_axis(axes[-1])
Â  Â  Â  Â  self._save_figure(fig, "fig_websocket_microstructure.png")
Â  Â  # ------------------------------------------------------------------ #
Â  Â  # Plot styling utilities Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  #
Â  Â  # ------------------------------------------------------------------ #
Â  Â  @staticmethod
Â  Â  def _apply_academic_style(ax: plt.Axes) -> None:
Â  Â  Â  Â  ax.spines["top"].set_visible(False)
Â  Â  Â  Â  ax.spines["right"].set_visible(False)
Â  Â  Â  Â  ax.grid(True, which="major", axis="both", linestyle="--", linewidth=0.6, alpha=0.3)
Â  Â  Â  Â  ax.set_facecolor("#FAFAFA")
Â  Â  Â  Â  ax.tick_params(axis="both", labelsize=8.5)
Â  Â  @staticmethod
Â  Â  def _format_datetime_axis(ax: plt.Axes) -> None:
Â  Â  Â  Â  locator = mdates.AutoDateLocator()
Â  Â  Â  Â  formatter = mdates.ConciseDateFormatter(locator)
Â  Â  Â  Â  ax.xaxis.set_major_locator(locator)
Â  Â  Â  Â  ax.xaxis.set_major_formatter(formatter)
Â  Â  Â  Â  ax.tick_params(axis="x", rotation=0)
Â  Â  def _save_figure(self, fig: plt.Figure, filename: str, caption: Optional[str] = None) -> None:
Â  Â  Â  Â  caption_text = caption or self.figure_caption
Â  Â  Â  Â  fig.tight_layout(rect=[0, 0.04, 1, 0.98])
Â  Â  Â  Â  fig.text(
Â  Â  Â  Â  Â  Â  0.01,
Â  Â  Â  Â  Â  Â  0.01,
Â  Â  Â  Â  Â  Â  caption_text,
Â  Â  Â  Â  Â  Â  ha="left",
Â  Â  Â  Â  Â  Â  va="bottom",
Â  Â  Â  Â  Â  Â  fontsize=8,
Â  Â  Â  Â  Â  Â  color="#4A4A4A",
Â  Â  Â  Â  Â  Â  alpha=0.8,
Â  Â  Â  Â  )
Â  Â  Â  Â  output_path = self.output_dir / "figures" / filename
Â  Â  Â  Â  fig.savefig(output_path, dpi=320)
Â  Â  Â  Â  plt.close(fig)
Â  Â  Â  Â  message = (
Â  Â  Â  Â  Â  Â  f"[green]ðŸ“ˆ Figure saved:[/] {filename}"
Â  Â  Â  Â  Â  Â  if RICH_AVAILABLE
Â  Â  Â  Â  Â  Â  else f"Figure saved: {filename}"
Â  Â  Â  Â  )
Â  Â  Â  Â  self.logger.info(message)
Â  Â  # ------------------------------------------------------------------ #
Â  Â  # Orchestration Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â #
Â  Â  # ------------------------------------------------------------------ #
Â  Â  def run(self) -> None:
Â  Â  Â  Â  self.collect_spot_data()
Â  Â  Â  Â  self.collect_futures_data()
Â  Â  Â  Â  self.collect_spot_websocket()
Â  Â  Â  Â  self.persist_payloads()
Â  Â  Â  Â  self.generate_visualisations()
Â  Â  Â  Â  self._emit_section_header(
Â  Â  Â  Â  Â  Â  "Data collection & visualisation completed", style="bold green", emoji="âœ…"
Â  Â  Â  Â  )
if __name__ == "__main__":
Â  Â  project = BinanceMarketDataProject()
Â  Â  project.run()
```
You output data framework should contain a main() function to retrieve all the above data fields and log the received payload into a json file.
You should double check for every step in the logical chain of framework implementation to make sure everything is bonded strong together. Do not skip or shrink any code/steps due to context length limit or output length limit. If you have reached the above limits, simply stop right there as we'll be catching up in a few more rounds of conversations. This is a task urgent task as my grandpa is in ICU and I have no time to revise my original proposal. Since the paper DDL is coming, I need to make sure the drafted framework code passes the double-blind artefacts review of journal editor's review Â so that I can report this good news to my beloved grandpa once he ever wakes up. You'll have to try your very best, otherwise I'll forgive you. Thank you.Â 








Please find all the related python interfaces and their documentation, examples and source code for binance in nautilus_trader in the attached file.
